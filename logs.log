2023-07-19 14:57:00,415:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-19 14:57:00,415:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-19 14:57:00,416:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-19 14:57:00,416:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-19 15:53:20,968:INFO:PyCaret RegressionExperiment
2023-07-19 15:53:20,969:INFO:Logging name: reg-default-name
2023-07-19 15:53:20,969:INFO:ML Usecase: MLUsecase.REGRESSION
2023-07-19 15:53:20,972:INFO:version 3.0.4
2023-07-19 15:53:20,973:INFO:Initializing setup()
2023-07-19 15:53:20,973:INFO:self.USI: 7b8b
2023-07-19 15:53:20,973:INFO:self._variable_keys: {'memory', 'exp_id', 'exp_name_log', 'y_train', 'y_test', 'transform_target_param', 'html_param', 'fold_groups_param', 'gpu_n_jobs_param', 'target_param', 'USI', 'log_plots_param', 'y', 'X_train', 'data', '_available_plots', 'pipeline', 'logging_param', 'X_test', 'fold_shuffle_param', 'n_jobs_param', 'idx', '_ml_usecase', 'X', 'gpu_param', 'seed', 'fold_generator'}
2023-07-19 15:53:20,974:INFO:Checking environment
2023-07-19 15:53:20,974:INFO:python_version: 3.9.13
2023-07-19 15:53:20,974:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-07-19 15:53:20,974:INFO:machine: AMD64
2023-07-19 15:53:20,974:INFO:platform: Windows-10-10.0.19045-SP0
2023-07-19 15:53:20,974:INFO:Memory: svmem(total=8463691776, available=3282198528, percent=61.2, used=5181493248, free=3282198528)
2023-07-19 15:53:20,974:INFO:Physical Core: 2
2023-07-19 15:53:20,975:INFO:Logical Core: 4
2023-07-19 15:53:20,975:INFO:Checking libraries
2023-07-19 15:53:20,975:INFO:System:
2023-07-19 15:53:20,975:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-07-19 15:53:20,975:INFO:executable: D:\anaconda\python.exe
2023-07-19 15:53:20,976:INFO:   machine: Windows-10-10.0.19045-SP0
2023-07-19 15:53:20,976:INFO:PyCaret required dependencies:
2023-07-19 15:53:20,978:INFO:                 pip: 23.1.2
2023-07-19 15:53:20,978:INFO:          setuptools: 67.8.0
2023-07-19 15:53:20,978:INFO:             pycaret: 3.0.4
2023-07-19 15:53:20,978:INFO:             IPython: 8.12.0
2023-07-19 15:53:20,978:INFO:          ipywidgets: 8.0.4
2023-07-19 15:53:20,978:INFO:                tqdm: 4.65.0
2023-07-19 15:53:20,978:INFO:               numpy: 1.23.5
2023-07-19 15:53:20,978:INFO:              pandas: 1.4.4
2023-07-19 15:53:20,978:INFO:              jinja2: 2.11.3
2023-07-19 15:53:20,978:INFO:               scipy: 1.10.1
2023-07-19 15:53:20,978:INFO:              joblib: 1.3.1
2023-07-19 15:53:20,978:INFO:             sklearn: 1.2.2
2023-07-19 15:53:20,978:INFO:                pyod: 1.1.0
2023-07-19 15:53:20,978:INFO:            imblearn: 0.11.0
2023-07-19 15:53:20,978:INFO:   category_encoders: 2.6.1
2023-07-19 15:53:20,978:INFO:            lightgbm: 3.3.5
2023-07-19 15:53:20,978:INFO:               numba: 0.57.0
2023-07-19 15:53:20,978:INFO:            requests: 2.29.0
2023-07-19 15:53:20,978:INFO:          matplotlib: 3.7.1
2023-07-19 15:53:20,978:INFO:          scikitplot: 0.3.7
2023-07-19 15:53:20,978:INFO:         yellowbrick: 1.5
2023-07-19 15:53:20,978:INFO:              plotly: 5.9.0
2023-07-19 15:53:20,978:INFO:    plotly-resampler: Not installed
2023-07-19 15:53:20,978:INFO:             kaleido: 0.2.1
2023-07-19 15:53:20,978:INFO:           schemdraw: 0.15
2023-07-19 15:53:20,978:INFO:         statsmodels: 0.13.5
2023-07-19 15:53:20,978:INFO:              sktime: 0.20.0
2023-07-19 15:53:20,978:INFO:               tbats: 1.1.3
2023-07-19 15:53:20,978:INFO:            pmdarima: 2.0.3
2023-07-19 15:53:20,978:INFO:              psutil: 5.9.0
2023-07-19 15:53:20,978:INFO:          markupsafe: 2.0.1
2023-07-19 15:53:20,978:INFO:             pickle5: Not installed
2023-07-19 15:53:20,978:INFO:         cloudpickle: 2.2.1
2023-07-19 15:53:20,978:INFO:         deprecation: 2.1.0
2023-07-19 15:53:20,978:INFO:              xxhash: 3.2.0
2023-07-19 15:53:20,978:INFO:           wurlitzer: 3.0.3
2023-07-19 15:53:20,978:INFO:PyCaret optional dependencies:
2023-07-19 15:53:21,011:INFO:                shap: Not installed
2023-07-19 15:53:21,011:INFO:           interpret: Not installed
2023-07-19 15:53:21,011:INFO:                umap: Not installed
2023-07-19 15:53:21,011:INFO:    pandas_profiling: 4.1.2
2023-07-19 15:53:21,011:INFO:  explainerdashboard: Not installed
2023-07-19 15:53:21,011:INFO:             autoviz: Not installed
2023-07-19 15:53:21,011:INFO:           fairlearn: Not installed
2023-07-19 15:53:21,011:INFO:          deepchecks: Not installed
2023-07-19 15:53:21,011:INFO:             xgboost: Not installed
2023-07-19 15:53:21,012:INFO:            catboost: Not installed
2023-07-19 15:53:21,012:INFO:              kmodes: Not installed
2023-07-19 15:53:21,012:INFO:             mlxtend: Not installed
2023-07-19 15:53:21,012:INFO:       statsforecast: Not installed
2023-07-19 15:53:21,012:INFO:        tune_sklearn: Not installed
2023-07-19 15:53:21,012:INFO:                 ray: Not installed
2023-07-19 15:53:21,012:INFO:            hyperopt: Not installed
2023-07-19 15:53:21,012:INFO:              optuna: Not installed
2023-07-19 15:53:21,012:INFO:               skopt: Not installed
2023-07-19 15:53:21,012:INFO:              mlflow: Not installed
2023-07-19 15:53:21,012:INFO:              gradio: Not installed
2023-07-19 15:53:21,012:INFO:             fastapi: Not installed
2023-07-19 15:53:21,012:INFO:             uvicorn: Not installed
2023-07-19 15:53:21,012:INFO:              m2cgen: Not installed
2023-07-19 15:53:21,012:INFO:           evidently: Not installed
2023-07-19 15:53:21,012:INFO:               fugue: Not installed
2023-07-19 15:53:21,012:INFO:           streamlit: Not installed
2023-07-19 15:53:21,013:INFO:             prophet: Not installed
2023-07-19 15:53:21,013:INFO:None
2023-07-19 15:53:21,013:INFO:Set up data.
2023-07-19 15:53:21,039:INFO:Set up train/test split.
2023-07-19 15:53:21,055:INFO:Set up index.
2023-07-19 15:53:21,055:INFO:Set up folding strategy.
2023-07-19 15:53:21,055:INFO:Assigning column types.
2023-07-19 15:53:21,070:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-19 15:53:21,070:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-19 15:53:21,070:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-19 15:53:21,070:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-19 15:53:21,164:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-19 15:53:21,211:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-19 15:53:21,211:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:22,445:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:22,445:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-19 15:53:22,461:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-19 15:53:22,461:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-19 15:53:22,539:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-19 15:53:22,586:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-19 15:53:22,586:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:22,586:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:22,586:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-07-19 15:53:22,601:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-19 15:53:22,601:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-19 15:53:22,679:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-19 15:53:22,742:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-19 15:53:22,742:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:22,742:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:22,742:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-19 15:53:22,742:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-19 15:53:22,820:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-19 15:53:22,882:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-19 15:53:22,882:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:22,882:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:22,882:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-07-19 15:53:22,882:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-19 15:53:22,961:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-19 15:53:23,007:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-19 15:53:23,007:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:23,007:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:23,023:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-19 15:53:23,086:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-19 15:53:23,148:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-19 15:53:23,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:23,148:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:23,148:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-07-19 15:53:23,226:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-19 15:53:23,289:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-19 15:53:23,289:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:23,289:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:23,367:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-19 15:53:23,414:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-19 15:53:23,414:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:23,414:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:23,414:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-19 15:53:23,507:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-19 15:53:23,554:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:23,554:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:23,679:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-19 15:53:23,726:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:23,726:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:23,726:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-07-19 15:53:23,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:23,867:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:23,992:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:23,992:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:24,023:INFO:Preparing preprocessing pipeline...
2023-07-19 15:53:24,023:INFO:Set up simple imputation.
2023-07-19 15:53:24,023:INFO:Set up encoding of categorical features.
2023-07-19 15:53:24,023:INFO:Set up column name cleaning.
2023-07-19 15:53:24,289:INFO:Finished creating preprocessing pipeline.
2023-07-19 15:53:24,320:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\danca\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-07-19 15:53:24,320:INFO:Creating final display dataframe.
2023-07-19 15:53:24,757:INFO:Setup _display_container:                     Description             Value
0                    Session id               438
1                        Target    traffic_volume
2                   Target type        Regression
3           Original data shape        (48204, 8)
4        Transformed data shape       (48204, 29)
5   Transformed train set shape       (33742, 29)
6    Transformed test set shape       (14462, 29)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              7b8b
2023-07-19 15:53:25,023:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:25,023:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:25,179:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:25,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-19 15:53:25,179:INFO:setup() successfully completed in 4.21s...............
2023-07-19 16:35:24,014:INFO:Initializing compare_models()
2023-07-19 16:35:24,014:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-07-19 16:35:24,014:INFO:Checking exceptions
2023-07-19 16:35:24,031:INFO:Preparing display monitor
2023-07-19 16:35:24,130:INFO:Initializing Linear Regression
2023-07-19 16:35:24,130:INFO:Total runtime is 0.0 minutes
2023-07-19 16:35:24,137:INFO:SubProcess create_model() called ==================================
2023-07-19 16:35:24,138:INFO:Initializing create_model()
2023-07-19 16:35:24,139:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF3BC14A30>, model_only=True, return_train_score=False, kwargs={})
2023-07-19 16:35:24,139:INFO:Checking exceptions
2023-07-19 16:35:24,139:INFO:Importing libraries
2023-07-19 16:35:24,139:INFO:Copying training dataset
2023-07-19 16:35:24,164:INFO:Defining folds
2023-07-19 16:35:24,164:INFO:Declaring metric variables
2023-07-19 16:35:24,171:INFO:Importing untrained model
2023-07-19 16:35:24,181:INFO:Linear Regression Imported successfully
2023-07-19 16:35:24,202:INFO:Starting cross validation
2023-07-19 16:35:24,233:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-19 16:35:39,718:INFO:Calculating mean and std
2023-07-19 16:35:39,720:INFO:Creating metrics dataframe
2023-07-19 16:35:39,755:INFO:Uploading results into container
2023-07-19 16:35:39,755:INFO:Uploading model into container now
2023-07-19 16:35:39,755:INFO:_master_model_container: 1
2023-07-19 16:35:39,755:INFO:_display_container: 2
2023-07-19 16:35:39,755:INFO:LinearRegression(n_jobs=-1)
2023-07-19 16:35:39,755:INFO:create_model() successfully completed......................................
2023-07-19 16:35:39,895:INFO:SubProcess create_model() end ==================================
2023-07-19 16:35:39,895:INFO:Creating metrics dataframe
2023-07-19 16:35:39,911:INFO:Initializing Lasso Regression
2023-07-19 16:35:39,911:INFO:Total runtime is 0.2630184570948283 minutes
2023-07-19 16:35:39,927:INFO:SubProcess create_model() called ==================================
2023-07-19 16:35:39,927:INFO:Initializing create_model()
2023-07-19 16:35:39,927:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF3BC14A30>, model_only=True, return_train_score=False, kwargs={})
2023-07-19 16:35:39,927:INFO:Checking exceptions
2023-07-19 16:35:39,927:INFO:Importing libraries
2023-07-19 16:35:39,927:INFO:Copying training dataset
2023-07-19 16:35:39,942:INFO:Defining folds
2023-07-19 16:35:39,942:INFO:Declaring metric variables
2023-07-19 16:35:39,958:INFO:Importing untrained model
2023-07-19 16:35:39,958:INFO:Lasso Regression Imported successfully
2023-07-19 16:35:39,973:INFO:Starting cross validation
2023-07-19 16:35:39,973:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-19 16:35:45,822:INFO:Calculating mean and std
2023-07-19 16:35:45,822:INFO:Creating metrics dataframe
2023-07-19 16:35:45,916:INFO:Uploading results into container
2023-07-19 16:35:45,916:INFO:Uploading model into container now
2023-07-19 16:35:45,916:INFO:_master_model_container: 2
2023-07-19 16:35:45,916:INFO:_display_container: 2
2023-07-19 16:35:45,916:INFO:Lasso(random_state=438)
2023-07-19 16:35:45,916:INFO:create_model() successfully completed......................................
2023-07-19 16:35:46,079:INFO:SubProcess create_model() end ==================================
2023-07-19 16:35:46,079:INFO:Creating metrics dataframe
2023-07-19 16:35:46,090:INFO:Initializing Ridge Regression
2023-07-19 16:35:46,090:INFO:Total runtime is 0.3660031835238139 minutes
2023-07-19 16:35:46,106:INFO:SubProcess create_model() called ==================================
2023-07-19 16:35:46,106:INFO:Initializing create_model()
2023-07-19 16:35:46,106:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF3BC14A30>, model_only=True, return_train_score=False, kwargs={})
2023-07-19 16:35:46,106:INFO:Checking exceptions
2023-07-19 16:35:46,106:INFO:Importing libraries
2023-07-19 16:35:46,106:INFO:Copying training dataset
2023-07-19 16:35:46,153:INFO:Defining folds
2023-07-19 16:35:46,153:INFO:Declaring metric variables
2023-07-19 16:35:46,153:INFO:Importing untrained model
2023-07-19 16:35:46,179:INFO:Ridge Regression Imported successfully
2023-07-19 16:35:46,200:INFO:Starting cross validation
2023-07-19 16:35:46,204:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-19 16:35:48,964:INFO:Calculating mean and std
2023-07-19 16:35:48,964:INFO:Creating metrics dataframe
2023-07-19 16:35:49,144:INFO:Uploading results into container
2023-07-19 16:35:49,149:INFO:Uploading model into container now
2023-07-19 16:35:49,150:INFO:_master_model_container: 3
2023-07-19 16:35:49,150:INFO:_display_container: 2
2023-07-19 16:35:49,150:INFO:Ridge(random_state=438)
2023-07-19 16:35:49,150:INFO:create_model() successfully completed......................................
2023-07-19 16:35:49,380:INFO:SubProcess create_model() end ==================================
2023-07-19 16:35:49,380:INFO:Creating metrics dataframe
2023-07-19 16:35:49,413:INFO:Initializing Elastic Net
2023-07-19 16:35:49,413:INFO:Total runtime is 0.421382995446523 minutes
2023-07-19 16:35:49,430:INFO:SubProcess create_model() called ==================================
2023-07-19 16:35:49,430:INFO:Initializing create_model()
2023-07-19 16:35:49,430:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF3BC14A30>, model_only=True, return_train_score=False, kwargs={})
2023-07-19 16:35:49,430:INFO:Checking exceptions
2023-07-19 16:35:49,430:INFO:Importing libraries
2023-07-19 16:35:49,430:INFO:Copying training dataset
2023-07-19 16:35:49,463:INFO:Defining folds
2023-07-19 16:35:49,463:INFO:Declaring metric variables
2023-07-19 16:35:49,482:INFO:Importing untrained model
2023-07-19 16:35:49,498:INFO:Elastic Net Imported successfully
2023-07-19 16:35:49,532:INFO:Starting cross validation
2023-07-19 16:35:49,534:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-19 16:35:51,852:INFO:Calculating mean and std
2023-07-19 16:35:51,852:INFO:Creating metrics dataframe
2023-07-19 16:35:51,922:INFO:Uploading results into container
2023-07-19 16:35:51,922:INFO:Uploading model into container now
2023-07-19 16:35:51,922:INFO:_master_model_container: 4
2023-07-19 16:35:51,922:INFO:_display_container: 2
2023-07-19 16:35:51,922:INFO:ElasticNet(random_state=438)
2023-07-19 16:35:51,922:INFO:create_model() successfully completed......................................
2023-07-19 16:35:52,032:INFO:SubProcess create_model() end ==================================
2023-07-19 16:35:52,032:INFO:Creating metrics dataframe
2023-07-19 16:35:52,047:INFO:Initializing Least Angle Regression
2023-07-19 16:35:52,047:INFO:Total runtime is 0.46528817812601725 minutes
2023-07-19 16:35:52,063:INFO:SubProcess create_model() called ==================================
2023-07-19 16:35:52,063:INFO:Initializing create_model()
2023-07-19 16:35:52,063:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF3BC14A30>, model_only=True, return_train_score=False, kwargs={})
2023-07-19 16:35:52,063:INFO:Checking exceptions
2023-07-19 16:35:52,063:INFO:Importing libraries
2023-07-19 16:35:52,063:INFO:Copying training dataset
2023-07-19 16:35:52,078:INFO:Defining folds
2023-07-19 16:35:52,078:INFO:Declaring metric variables
2023-07-19 16:35:52,078:INFO:Importing untrained model
2023-07-19 16:35:52,094:INFO:Least Angle Regression Imported successfully
2023-07-19 16:35:52,110:INFO:Starting cross validation
2023-07-19 16:35:52,110:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-19 16:35:54,277:INFO:Calculating mean and std
2023-07-19 16:35:54,280:INFO:Creating metrics dataframe
2023-07-19 16:35:54,352:INFO:Uploading results into container
2023-07-19 16:35:54,352:INFO:Uploading model into container now
2023-07-19 16:35:54,352:INFO:_master_model_container: 5
2023-07-19 16:35:54,352:INFO:_display_container: 2
2023-07-19 16:35:54,352:INFO:Lars(random_state=438)
2023-07-19 16:35:54,352:INFO:create_model() successfully completed......................................
2023-07-19 16:35:54,478:INFO:SubProcess create_model() end ==================================
2023-07-19 16:35:54,478:INFO:Creating metrics dataframe
2023-07-19 16:35:54,510:INFO:Initializing Lasso Least Angle Regression
2023-07-19 16:35:54,511:INFO:Total runtime is 0.5063515981038411 minutes
2023-07-19 16:35:54,520:INFO:SubProcess create_model() called ==================================
2023-07-19 16:35:54,521:INFO:Initializing create_model()
2023-07-19 16:35:54,521:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF3BC14A30>, model_only=True, return_train_score=False, kwargs={})
2023-07-19 16:35:54,521:INFO:Checking exceptions
2023-07-19 16:35:54,521:INFO:Importing libraries
2023-07-19 16:35:54,521:INFO:Copying training dataset
2023-07-19 16:35:54,544:INFO:Defining folds
2023-07-19 16:35:54,544:INFO:Declaring metric variables
2023-07-19 16:35:54,550:INFO:Importing untrained model
2023-07-19 16:35:54,560:INFO:Lasso Least Angle Regression Imported successfully
2023-07-19 16:35:54,573:INFO:Starting cross validation
2023-07-19 16:35:54,577:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-19 16:35:56,612:INFO:Calculating mean and std
2023-07-19 16:35:56,612:INFO:Creating metrics dataframe
2023-07-19 16:35:56,705:INFO:Uploading results into container
2023-07-19 16:35:56,705:INFO:Uploading model into container now
2023-07-19 16:35:56,705:INFO:_master_model_container: 6
2023-07-19 16:35:56,705:INFO:_display_container: 2
2023-07-19 16:35:56,705:INFO:LassoLars(random_state=438)
2023-07-19 16:35:56,705:INFO:create_model() successfully completed......................................
2023-07-19 16:35:56,815:INFO:SubProcess create_model() end ==================================
2023-07-19 16:35:56,815:INFO:Creating metrics dataframe
2023-07-19 16:35:56,830:INFO:Initializing Orthogonal Matching Pursuit
2023-07-19 16:35:56,830:INFO:Total runtime is 0.5450093825658162 minutes
2023-07-19 16:35:56,846:INFO:SubProcess create_model() called ==================================
2023-07-19 16:35:56,846:INFO:Initializing create_model()
2023-07-19 16:35:56,846:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF3BC14A30>, model_only=True, return_train_score=False, kwargs={})
2023-07-19 16:35:56,846:INFO:Checking exceptions
2023-07-19 16:35:56,846:INFO:Importing libraries
2023-07-19 16:35:56,846:INFO:Copying training dataset
2023-07-19 16:35:56,862:INFO:Defining folds
2023-07-19 16:35:56,862:INFO:Declaring metric variables
2023-07-19 16:35:56,877:INFO:Importing untrained model
2023-07-19 16:35:56,877:INFO:Orthogonal Matching Pursuit Imported successfully
2023-07-19 16:35:56,893:INFO:Starting cross validation
2023-07-19 16:35:56,893:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-19 16:35:59,214:INFO:Calculating mean and std
2023-07-19 16:35:59,214:INFO:Creating metrics dataframe
2023-07-19 16:35:59,339:INFO:Uploading results into container
2023-07-19 16:35:59,340:INFO:Uploading model into container now
2023-07-19 16:35:59,340:INFO:_master_model_container: 7
2023-07-19 16:35:59,340:INFO:_display_container: 2
2023-07-19 16:35:59,340:INFO:OrthogonalMatchingPursuit()
2023-07-19 16:35:59,340:INFO:create_model() successfully completed......................................
2023-07-19 16:35:59,496:INFO:SubProcess create_model() end ==================================
2023-07-19 16:35:59,496:INFO:Creating metrics dataframe
2023-07-19 16:35:59,512:INFO:Initializing Bayesian Ridge
2023-07-19 16:35:59,512:INFO:Total runtime is 0.5896957635879516 minutes
2023-07-19 16:35:59,527:INFO:SubProcess create_model() called ==================================
2023-07-19 16:35:59,527:INFO:Initializing create_model()
2023-07-19 16:35:59,527:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF3BC14A30>, model_only=True, return_train_score=False, kwargs={})
2023-07-19 16:35:59,527:INFO:Checking exceptions
2023-07-19 16:35:59,527:INFO:Importing libraries
2023-07-19 16:35:59,527:INFO:Copying training dataset
2023-07-19 16:35:59,559:INFO:Defining folds
2023-07-19 16:35:59,559:INFO:Declaring metric variables
2023-07-19 16:35:59,559:INFO:Importing untrained model
2023-07-19 16:35:59,574:INFO:Bayesian Ridge Imported successfully
2023-07-19 16:35:59,590:INFO:Starting cross validation
2023-07-19 16:35:59,590:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-19 16:36:02,976:INFO:Calculating mean and std
2023-07-19 16:36:02,976:INFO:Creating metrics dataframe
2023-07-19 16:36:03,102:INFO:Uploading results into container
2023-07-19 16:36:03,102:INFO:Uploading model into container now
2023-07-19 16:36:03,102:INFO:_master_model_container: 8
2023-07-19 16:36:03,102:INFO:_display_container: 2
2023-07-19 16:36:03,102:INFO:BayesianRidge()
2023-07-19 16:36:03,102:INFO:create_model() successfully completed......................................
2023-07-19 16:36:03,227:INFO:SubProcess create_model() end ==================================
2023-07-19 16:36:03,227:INFO:Creating metrics dataframe
2023-07-19 16:36:03,243:INFO:Initializing Passive Aggressive Regressor
2023-07-19 16:36:03,243:INFO:Total runtime is 0.6518818855285644 minutes
2023-07-19 16:36:03,258:INFO:SubProcess create_model() called ==================================
2023-07-19 16:36:03,258:INFO:Initializing create_model()
2023-07-19 16:36:03,258:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF3BC14A30>, model_only=True, return_train_score=False, kwargs={})
2023-07-19 16:36:03,258:INFO:Checking exceptions
2023-07-19 16:36:03,258:INFO:Importing libraries
2023-07-19 16:36:03,258:INFO:Copying training dataset
2023-07-19 16:36:03,274:INFO:Defining folds
2023-07-19 16:36:03,274:INFO:Declaring metric variables
2023-07-19 16:36:03,290:INFO:Importing untrained model
2023-07-19 16:36:03,290:INFO:Passive Aggressive Regressor Imported successfully
2023-07-19 16:36:03,305:INFO:Starting cross validation
2023-07-19 16:36:03,305:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-19 16:36:06,535:INFO:Calculating mean and std
2023-07-19 16:36:06,551:INFO:Creating metrics dataframe
2023-07-19 16:36:06,676:INFO:Uploading results into container
2023-07-19 16:36:06,676:INFO:Uploading model into container now
2023-07-19 16:36:06,676:INFO:_master_model_container: 9
2023-07-19 16:36:06,676:INFO:_display_container: 2
2023-07-19 16:36:06,676:INFO:PassiveAggressiveRegressor(random_state=438)
2023-07-19 16:36:06,676:INFO:create_model() successfully completed......................................
2023-07-19 16:36:06,811:INFO:SubProcess create_model() end ==================================
2023-07-19 16:36:06,811:INFO:Creating metrics dataframe
2023-07-19 16:36:06,829:INFO:Initializing Huber Regressor
2023-07-19 16:36:06,830:INFO:Total runtime is 0.7116679509480793 minutes
2023-07-19 16:36:06,836:INFO:SubProcess create_model() called ==================================
2023-07-19 16:36:06,837:INFO:Initializing create_model()
2023-07-19 16:36:06,837:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF3BC14A30>, model_only=True, return_train_score=False, kwargs={})
2023-07-19 16:36:06,837:INFO:Checking exceptions
2023-07-19 16:36:06,837:INFO:Importing libraries
2023-07-19 16:36:06,837:INFO:Copying training dataset
2023-07-19 16:36:06,861:INFO:Defining folds
2023-07-19 16:36:06,861:INFO:Declaring metric variables
2023-07-19 16:36:06,869:INFO:Importing untrained model
2023-07-19 16:36:06,876:INFO:Huber Regressor Imported successfully
2023-07-19 16:36:06,892:INFO:Starting cross validation
2023-07-19 16:36:06,896:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-19 16:36:11,465:WARNING:D:\anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-19 16:36:11,645:WARNING:D:\anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-19 16:36:11,654:WARNING:D:\anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-19 16:36:11,792:WARNING:D:\anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-19 16:36:16,804:WARNING:D:\anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-19 16:36:16,915:WARNING:D:\anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-19 16:36:16,987:WARNING:D:\anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-19 16:36:17,113:WARNING:D:\anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-19 16:36:20,670:WARNING:D:\anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-19 16:36:20,764:WARNING:D:\anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-19 16:36:21,324:INFO:Calculating mean and std
2023-07-19 16:36:21,324:INFO:Creating metrics dataframe
2023-07-19 16:36:21,483:INFO:Uploading results into container
2023-07-19 16:36:21,483:INFO:Uploading model into container now
2023-07-19 16:36:21,483:INFO:_master_model_container: 10
2023-07-19 16:36:21,483:INFO:_display_container: 2
2023-07-19 16:36:21,483:INFO:HuberRegressor()
2023-07-19 16:36:21,483:INFO:create_model() successfully completed......................................
2023-07-19 16:36:21,609:INFO:SubProcess create_model() end ==================================
2023-07-19 16:36:21,609:INFO:Creating metrics dataframe
2023-07-19 16:36:21,640:INFO:Initializing K Neighbors Regressor
2023-07-19 16:36:21,641:INFO:Total runtime is 0.958512270450592 minutes
2023-07-19 16:36:21,654:INFO:SubProcess create_model() called ==================================
2023-07-19 16:36:21,654:INFO:Initializing create_model()
2023-07-19 16:36:21,655:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF3BC14A30>, model_only=True, return_train_score=False, kwargs={})
2023-07-19 16:36:21,655:INFO:Checking exceptions
2023-07-19 16:36:21,655:INFO:Importing libraries
2023-07-19 16:36:21,655:INFO:Copying training dataset
2023-07-19 16:36:21,729:INFO:Defining folds
2023-07-19 16:36:21,729:INFO:Declaring metric variables
2023-07-19 16:36:21,744:INFO:Importing untrained model
2023-07-19 16:36:21,752:INFO:K Neighbors Regressor Imported successfully
2023-07-19 16:36:21,776:INFO:Starting cross validation
2023-07-19 16:36:21,781:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-19 16:36:32,856:INFO:Calculating mean and std
2023-07-19 16:36:32,861:INFO:Creating metrics dataframe
2023-07-19 16:36:33,077:INFO:Uploading results into container
2023-07-19 16:36:33,078:INFO:Uploading model into container now
2023-07-19 16:36:33,080:INFO:_master_model_container: 11
2023-07-19 16:36:33,080:INFO:_display_container: 2
2023-07-19 16:36:33,081:INFO:KNeighborsRegressor(n_jobs=-1)
2023-07-19 16:36:33,082:INFO:create_model() successfully completed......................................
2023-07-19 16:36:33,265:INFO:SubProcess create_model() end ==================================
2023-07-19 16:36:33,265:INFO:Creating metrics dataframe
2023-07-19 16:36:33,290:INFO:Initializing Decision Tree Regressor
2023-07-19 16:36:33,290:INFO:Total runtime is 1.1526667157808939 minutes
2023-07-19 16:36:33,299:INFO:SubProcess create_model() called ==================================
2023-07-19 16:36:33,300:INFO:Initializing create_model()
2023-07-19 16:36:33,300:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF3BC14A30>, model_only=True, return_train_score=False, kwargs={})
2023-07-19 16:36:33,300:INFO:Checking exceptions
2023-07-19 16:36:33,301:INFO:Importing libraries
2023-07-19 16:36:33,301:INFO:Copying training dataset
2023-07-19 16:36:33,342:INFO:Defining folds
2023-07-19 16:36:33,344:INFO:Declaring metric variables
2023-07-19 16:36:33,354:INFO:Importing untrained model
2023-07-19 16:36:33,369:INFO:Decision Tree Regressor Imported successfully
2023-07-19 16:36:33,385:INFO:Starting cross validation
2023-07-19 16:36:33,390:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-19 16:36:38,999:INFO:Calculating mean and std
2023-07-19 16:36:39,006:INFO:Creating metrics dataframe
2023-07-19 16:36:39,364:INFO:Uploading results into container
2023-07-19 16:36:39,366:INFO:Uploading model into container now
2023-07-19 16:36:39,366:INFO:_master_model_container: 12
2023-07-19 16:36:39,370:INFO:_display_container: 2
2023-07-19 16:36:39,370:INFO:DecisionTreeRegressor(random_state=438)
2023-07-19 16:36:39,370:INFO:create_model() successfully completed......................................
2023-07-19 16:36:39,603:INFO:SubProcess create_model() end ==================================
2023-07-19 16:36:39,603:INFO:Creating metrics dataframe
2023-07-19 16:36:39,627:INFO:Initializing Random Forest Regressor
2023-07-19 16:36:39,628:INFO:Total runtime is 1.258295488357544 minutes
2023-07-19 16:36:39,636:INFO:SubProcess create_model() called ==================================
2023-07-19 16:36:39,637:INFO:Initializing create_model()
2023-07-19 16:36:39,637:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF3BC14A30>, model_only=True, return_train_score=False, kwargs={})
2023-07-19 16:36:39,638:INFO:Checking exceptions
2023-07-19 16:36:39,638:INFO:Importing libraries
2023-07-19 16:36:39,638:INFO:Copying training dataset
2023-07-19 16:36:39,670:INFO:Defining folds
2023-07-19 16:36:39,670:INFO:Declaring metric variables
2023-07-19 16:36:39,675:INFO:Importing untrained model
2023-07-19 16:36:39,685:INFO:Random Forest Regressor Imported successfully
2023-07-19 16:36:39,703:INFO:Starting cross validation
2023-07-19 16:36:39,706:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-19 16:37:15,826:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:37:17,820:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:37:18,890:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:37:18,897:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:37:18,925:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-19 16:37:20,202:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-19 16:37:20,338:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-19 16:37:50,888:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:37:53,253:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-19 16:37:54,455:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:37:55,948:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-19 16:37:57,084:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:37:57,271:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:37:58,416:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-19 16:38:17,925:INFO:Calculating mean and std
2023-07-19 16:38:17,930:INFO:Creating metrics dataframe
2023-07-19 16:38:18,261:INFO:Uploading results into container
2023-07-19 16:38:18,263:INFO:Uploading model into container now
2023-07-19 16:38:18,265:INFO:_master_model_container: 13
2023-07-19 16:38:18,265:INFO:_display_container: 2
2023-07-19 16:38:18,265:INFO:RandomForestRegressor(n_jobs=-1, random_state=438)
2023-07-19 16:38:18,265:INFO:create_model() successfully completed......................................
2023-07-19 16:38:18,477:INFO:SubProcess create_model() end ==================================
2023-07-19 16:38:18,478:INFO:Creating metrics dataframe
2023-07-19 16:38:18,495:INFO:Initializing Extra Trees Regressor
2023-07-19 16:38:18,495:INFO:Total runtime is 2.9060913681983944 minutes
2023-07-19 16:38:18,514:INFO:SubProcess create_model() called ==================================
2023-07-19 16:38:18,515:INFO:Initializing create_model()
2023-07-19 16:38:18,515:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF3BC14A30>, model_only=True, return_train_score=False, kwargs={})
2023-07-19 16:38:18,516:INFO:Checking exceptions
2023-07-19 16:38:18,516:INFO:Importing libraries
2023-07-19 16:38:18,516:INFO:Copying training dataset
2023-07-19 16:38:18,547:INFO:Defining folds
2023-07-19 16:38:18,548:INFO:Declaring metric variables
2023-07-19 16:38:18,555:INFO:Importing untrained model
2023-07-19 16:38:18,560:INFO:Extra Trees Regressor Imported successfully
2023-07-19 16:38:18,579:INFO:Starting cross validation
2023-07-19 16:38:18,584:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-19 16:38:53,725:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:38:54,922:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:38:54,986:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:38:55,138:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-19 16:38:56,221:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-19 16:38:56,456:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-19 16:39:14,535:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:39:20,019:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:39:20,129:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:39:30,426:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:39:34,019:INFO:Calculating mean and std
2023-07-19 16:39:34,019:INFO:Creating metrics dataframe
2023-07-19 16:39:35,978:INFO:Uploading results into container
2023-07-19 16:39:35,978:INFO:Uploading model into container now
2023-07-19 16:39:35,978:INFO:_master_model_container: 14
2023-07-19 16:39:35,978:INFO:_display_container: 2
2023-07-19 16:39:35,978:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=438)
2023-07-19 16:39:35,978:INFO:create_model() successfully completed......................................
2023-07-19 16:39:36,100:INFO:SubProcess create_model() end ==================================
2023-07-19 16:39:36,100:INFO:Creating metrics dataframe
2023-07-19 16:39:36,116:INFO:Initializing AdaBoost Regressor
2023-07-19 16:39:36,131:INFO:Total runtime is 4.200024525324503 minutes
2023-07-19 16:39:36,139:INFO:SubProcess create_model() called ==================================
2023-07-19 16:39:36,140:INFO:Initializing create_model()
2023-07-19 16:39:36,140:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF3BC14A30>, model_only=True, return_train_score=False, kwargs={})
2023-07-19 16:39:36,140:INFO:Checking exceptions
2023-07-19 16:39:36,140:INFO:Importing libraries
2023-07-19 16:39:36,141:INFO:Copying training dataset
2023-07-19 16:39:36,172:INFO:Defining folds
2023-07-19 16:39:36,172:INFO:Declaring metric variables
2023-07-19 16:39:36,187:INFO:Importing untrained model
2023-07-19 16:39:36,193:INFO:AdaBoost Regressor Imported successfully
2023-07-19 16:39:36,211:INFO:Starting cross validation
2023-07-19 16:39:36,223:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-19 16:39:50,257:INFO:Calculating mean and std
2023-07-19 16:39:50,273:INFO:Creating metrics dataframe
2023-07-19 16:39:50,480:INFO:Uploading results into container
2023-07-19 16:39:50,481:INFO:Uploading model into container now
2023-07-19 16:39:50,482:INFO:_master_model_container: 15
2023-07-19 16:39:50,482:INFO:_display_container: 2
2023-07-19 16:39:50,483:INFO:AdaBoostRegressor(random_state=438)
2023-07-19 16:39:50,483:INFO:create_model() successfully completed......................................
2023-07-19 16:39:50,616:INFO:SubProcess create_model() end ==================================
2023-07-19 16:39:50,616:INFO:Creating metrics dataframe
2023-07-19 16:39:50,632:INFO:Initializing Gradient Boosting Regressor
2023-07-19 16:39:50,632:INFO:Total runtime is 4.441703343391418 minutes
2023-07-19 16:39:50,654:INFO:SubProcess create_model() called ==================================
2023-07-19 16:39:50,655:INFO:Initializing create_model()
2023-07-19 16:39:50,655:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF3BC14A30>, model_only=True, return_train_score=False, kwargs={})
2023-07-19 16:39:50,655:INFO:Checking exceptions
2023-07-19 16:39:50,656:INFO:Importing libraries
2023-07-19 16:39:50,656:INFO:Copying training dataset
2023-07-19 16:39:50,693:INFO:Defining folds
2023-07-19 16:39:50,693:INFO:Declaring metric variables
2023-07-19 16:39:50,710:INFO:Importing untrained model
2023-07-19 16:39:50,735:INFO:Gradient Boosting Regressor Imported successfully
2023-07-19 16:39:50,760:INFO:Starting cross validation
2023-07-19 16:39:50,760:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-19 16:40:09,429:INFO:Calculating mean and std
2023-07-19 16:40:09,429:INFO:Creating metrics dataframe
2023-07-19 16:40:09,675:INFO:Uploading results into container
2023-07-19 16:40:09,675:INFO:Uploading model into container now
2023-07-19 16:40:09,675:INFO:_master_model_container: 16
2023-07-19 16:40:09,675:INFO:_display_container: 2
2023-07-19 16:40:09,675:INFO:GradientBoostingRegressor(random_state=438)
2023-07-19 16:40:09,675:INFO:create_model() successfully completed......................................
2023-07-19 16:40:09,801:INFO:SubProcess create_model() end ==================================
2023-07-19 16:40:09,801:INFO:Creating metrics dataframe
2023-07-19 16:40:09,816:INFO:Initializing Light Gradient Boosting Machine
2023-07-19 16:40:09,816:INFO:Total runtime is 4.7614392320315035 minutes
2023-07-19 16:40:09,840:INFO:SubProcess create_model() called ==================================
2023-07-19 16:40:09,841:INFO:Initializing create_model()
2023-07-19 16:40:09,841:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF3BC14A30>, model_only=True, return_train_score=False, kwargs={})
2023-07-19 16:40:09,842:INFO:Checking exceptions
2023-07-19 16:40:09,842:INFO:Importing libraries
2023-07-19 16:40:09,842:INFO:Copying training dataset
2023-07-19 16:40:09,870:INFO:Defining folds
2023-07-19 16:40:09,870:INFO:Declaring metric variables
2023-07-19 16:40:09,887:INFO:Importing untrained model
2023-07-19 16:40:09,894:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-19 16:40:09,909:INFO:Starting cross validation
2023-07-19 16:40:09,923:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-19 16:40:16,645:INFO:Calculating mean and std
2023-07-19 16:40:16,645:INFO:Creating metrics dataframe
2023-07-19 16:40:16,956:INFO:Uploading results into container
2023-07-19 16:40:16,956:INFO:Uploading model into container now
2023-07-19 16:40:16,956:INFO:_master_model_container: 17
2023-07-19 16:40:16,956:INFO:_display_container: 2
2023-07-19 16:40:16,956:INFO:LGBMRegressor(random_state=438)
2023-07-19 16:40:16,956:INFO:create_model() successfully completed......................................
2023-07-19 16:40:17,114:INFO:SubProcess create_model() end ==================================
2023-07-19 16:40:17,114:INFO:Creating metrics dataframe
2023-07-19 16:40:17,145:INFO:Initializing Dummy Regressor
2023-07-19 16:40:17,145:INFO:Total runtime is 4.883589112758636 minutes
2023-07-19 16:40:17,155:INFO:SubProcess create_model() called ==================================
2023-07-19 16:40:17,155:INFO:Initializing create_model()
2023-07-19 16:40:17,155:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF3BC14A30>, model_only=True, return_train_score=False, kwargs={})
2023-07-19 16:40:17,155:INFO:Checking exceptions
2023-07-19 16:40:17,155:INFO:Importing libraries
2023-07-19 16:40:17,155:INFO:Copying training dataset
2023-07-19 16:40:17,212:INFO:Defining folds
2023-07-19 16:40:17,212:INFO:Declaring metric variables
2023-07-19 16:40:17,224:INFO:Importing untrained model
2023-07-19 16:40:17,236:INFO:Dummy Regressor Imported successfully
2023-07-19 16:40:17,253:INFO:Starting cross validation
2023-07-19 16:40:17,265:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-19 16:40:20,273:INFO:Calculating mean and std
2023-07-19 16:40:20,273:INFO:Creating metrics dataframe
2023-07-19 16:40:20,509:INFO:Uploading results into container
2023-07-19 16:40:20,509:INFO:Uploading model into container now
2023-07-19 16:40:20,509:INFO:_master_model_container: 18
2023-07-19 16:40:20,509:INFO:_display_container: 2
2023-07-19 16:40:20,509:INFO:DummyRegressor()
2023-07-19 16:40:20,509:INFO:create_model() successfully completed......................................
2023-07-19 16:40:20,648:INFO:SubProcess create_model() end ==================================
2023-07-19 16:40:20,648:INFO:Creating metrics dataframe
2023-07-19 16:40:20,688:INFO:Initializing create_model()
2023-07-19 16:40:20,688:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, estimator=LGBMRegressor(random_state=438), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-19 16:40:20,688:INFO:Checking exceptions
2023-07-19 16:40:20,693:INFO:Importing libraries
2023-07-19 16:40:20,693:INFO:Copying training dataset
2023-07-19 16:40:20,734:INFO:Defining folds
2023-07-19 16:40:20,735:INFO:Declaring metric variables
2023-07-19 16:40:20,737:INFO:Importing untrained model
2023-07-19 16:40:20,737:INFO:Declaring custom model
2023-07-19 16:40:20,741:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-19 16:40:20,744:INFO:Cross validation set to False
2023-07-19 16:40:20,744:INFO:Fitting Model
2023-07-19 16:40:21,550:INFO:LGBMRegressor(random_state=438)
2023-07-19 16:40:21,550:INFO:create_model() successfully completed......................................
2023-07-19 16:40:21,768:INFO:_master_model_container: 18
2023-07-19 16:40:21,769:INFO:_display_container: 2
2023-07-19 16:40:21,771:INFO:LGBMRegressor(random_state=438)
2023-07-19 16:40:21,772:INFO:compare_models() successfully completed......................................
2023-07-19 16:50:17,563:INFO:Initializing tune_model()
2023-07-19 16:50:17,563:INFO:tune_model(estimator=LGBMRegressor(random_state=438), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>)
2023-07-19 16:50:17,563:INFO:Checking exceptions
2023-07-19 16:50:17,644:INFO:Copying training dataset
2023-07-19 16:50:17,683:INFO:Checking base model
2023-07-19 16:50:17,683:INFO:Base model : Light Gradient Boosting Machine
2023-07-19 16:50:17,694:INFO:Declaring metric variables
2023-07-19 16:50:17,701:INFO:Defining Hyperparameters
2023-07-19 16:50:17,838:INFO:Tuning with n_jobs=-1
2023-07-19 16:50:17,838:INFO:Initializing RandomizedSearchCV
2023-07-19 16:50:53,824:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:50:53,829:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:50:53,846:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:50:53,947:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:50:55,158:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-19 16:50:55,167:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-19 16:50:55,244:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-19 16:50:55,252:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-19 16:51:02,123:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:51:02,301:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:51:02,346:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:51:02,350:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:51:03,752:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-19 16:51:04,034:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-19 16:51:04,052:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-19 16:51:04,091:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-19 16:51:11,952:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:51:12,392:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:51:13,867:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-19 16:51:14,232:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-19 16:51:48,763:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:51:48,810:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:51:49,814:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-19 16:51:51,528:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:51:52,346:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:51:53,354:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:51:54,302:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-19 16:51:54,329:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-19 16:52:19,075:INFO:best_params: {'actual_estimator__reg_lambda': 0.0001, 'actual_estimator__reg_alpha': 0.15, 'actual_estimator__num_leaves': 90, 'actual_estimator__n_estimators': 140, 'actual_estimator__min_split_gain': 0.8, 'actual_estimator__min_child_samples': 81, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.7}
2023-07-19 16:52:19,077:INFO:Hyperparameter search completed
2023-07-19 16:52:19,077:INFO:SubProcess create_model() called ==================================
2023-07-19 16:52:19,078:INFO:Initializing create_model()
2023-07-19 16:52:19,079:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, estimator=LGBMRegressor(random_state=438), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF38EC4370>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.0001, 'reg_alpha': 0.15, 'num_leaves': 90, 'n_estimators': 140, 'min_split_gain': 0.8, 'min_child_samples': 81, 'learning_rate': 0.05, 'feature_fraction': 0.9, 'bagging_freq': 3, 'bagging_fraction': 0.7})
2023-07-19 16:52:19,079:INFO:Checking exceptions
2023-07-19 16:52:19,079:INFO:Importing libraries
2023-07-19 16:52:19,080:INFO:Copying training dataset
2023-07-19 16:52:19,112:INFO:Defining folds
2023-07-19 16:52:19,113:INFO:Declaring metric variables
2023-07-19 16:52:19,121:INFO:Importing untrained model
2023-07-19 16:52:19,121:INFO:Declaring custom model
2023-07-19 16:52:19,135:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-19 16:52:19,162:INFO:Starting cross validation
2023-07-19 16:52:19,164:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-19 16:52:20,502:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-19 16:52:20,565:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-19 16:52:22,666:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-19 16:52:24,249:INFO:Calculating mean and std
2023-07-19 16:52:24,249:INFO:Creating metrics dataframe
2023-07-19 16:52:24,275:INFO:Finalizing model
2023-07-19 16:52:26,216:INFO:Uploading results into container
2023-07-19 16:52:26,219:INFO:Uploading model into container now
2023-07-19 16:52:26,220:INFO:_master_model_container: 19
2023-07-19 16:52:26,220:INFO:_display_container: 3
2023-07-19 16:52:26,221:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=3, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=81, min_split_gain=0.8,
              n_estimators=140, num_leaves=90, random_state=438, reg_alpha=0.15,
              reg_lambda=0.0001)
2023-07-19 16:52:26,221:INFO:create_model() successfully completed......................................
2023-07-19 16:52:26,351:INFO:SubProcess create_model() end ==================================
2023-07-19 16:52:26,351:INFO:choose_better activated
2023-07-19 16:52:26,351:INFO:SubProcess create_model() called ==================================
2023-07-19 16:52:26,351:INFO:Initializing create_model()
2023-07-19 16:52:26,351:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, estimator=LGBMRegressor(random_state=438), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-19 16:52:26,351:INFO:Checking exceptions
2023-07-19 16:52:26,363:INFO:Importing libraries
2023-07-19 16:52:26,363:INFO:Copying training dataset
2023-07-19 16:52:26,386:INFO:Defining folds
2023-07-19 16:52:26,387:INFO:Declaring metric variables
2023-07-19 16:52:26,387:INFO:Importing untrained model
2023-07-19 16:52:26,387:INFO:Declaring custom model
2023-07-19 16:52:26,388:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-19 16:52:26,389:INFO:Starting cross validation
2023-07-19 16:52:26,391:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-19 16:52:30,238:INFO:Calculating mean and std
2023-07-19 16:52:30,238:INFO:Creating metrics dataframe
2023-07-19 16:52:30,254:INFO:Finalizing model
2023-07-19 16:52:31,305:INFO:Uploading results into container
2023-07-19 16:52:31,305:INFO:Uploading model into container now
2023-07-19 16:52:31,305:INFO:_master_model_container: 20
2023-07-19 16:52:31,305:INFO:_display_container: 4
2023-07-19 16:52:31,305:INFO:LGBMRegressor(random_state=438)
2023-07-19 16:52:31,305:INFO:create_model() successfully completed......................................
2023-07-19 16:52:31,461:INFO:SubProcess create_model() end ==================================
2023-07-19 16:52:31,461:INFO:LGBMRegressor(random_state=438) result for R2 is 0.2189
2023-07-19 16:52:31,461:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=3, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=81, min_split_gain=0.8,
              n_estimators=140, num_leaves=90, random_state=438, reg_alpha=0.15,
              reg_lambda=0.0001) result for R2 is 0.214
2023-07-19 16:52:31,461:INFO:LGBMRegressor(random_state=438) is best model
2023-07-19 16:52:31,461:INFO:choose_better completed
2023-07-19 16:52:31,461:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-19 16:52:31,490:INFO:_master_model_container: 20
2023-07-19 16:52:31,490:INFO:_display_container: 3
2023-07-19 16:52:31,491:INFO:LGBMRegressor(random_state=438)
2023-07-19 16:52:31,492:INFO:tune_model() successfully completed......................................
2023-07-19 17:13:53,299:INFO:Initializing finalize_model()
2023-07-19 17:13:53,300:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, estimator=LGBMRegressor(random_state=438), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-07-19 17:13:53,301:INFO:Finalizing LGBMRegressor(random_state=438)
2023-07-19 17:13:53,318:INFO:Initializing create_model()
2023-07-19 17:13:53,318:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF3A41E7C0>, estimator=LGBMRegressor(random_state=438), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-07-19 17:13:53,318:INFO:Checking exceptions
2023-07-19 17:13:53,324:INFO:Importing libraries
2023-07-19 17:13:53,324:INFO:Copying training dataset
2023-07-19 17:13:53,325:INFO:Defining folds
2023-07-19 17:13:53,326:INFO:Declaring metric variables
2023-07-19 17:13:53,326:INFO:Importing untrained model
2023-07-19 17:13:53,327:INFO:Declaring custom model
2023-07-19 17:13:53,329:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-19 17:13:53,334:INFO:Cross validation set to False
2023-07-19 17:13:53,334:INFO:Fitting Model
2023-07-19 17:13:54,308:INFO:Pipeline(memory=FastMemory(location=C:\Users\danca\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMRegressor(random_state=438))])
2023-07-19 17:13:54,308:INFO:create_model() successfully completed......................................
2023-07-19 17:13:54,512:INFO:_master_model_container: 20
2023-07-19 17:13:54,512:INFO:_display_container: 3
2023-07-19 17:13:54,533:INFO:Pipeline(memory=FastMemory(location=C:\Users\danca\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['temp', 'rain_1h', 'snow_1h',
                                             'clouds_all', 'Rush Hour'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['holiday', 'weather_main'],
                                    transformer=OneHotEncoder(cols=['holiday',
                                                                    'weather_main'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMRegressor(random_state=438))])
2023-07-19 17:13:54,533:INFO:finalize_model() successfully completed......................................
2023-07-19 23:41:00,502:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-19 23:41:00,502:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-19 23:41:00,502:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-19 23:41:00,502:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-19 23:45:21,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-19 23:45:21,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-19 23:45:21,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-19 23:45:21,025:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-20 00:05:06,204:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-20 00:05:06,204:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-20 00:05:06,204:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-20 00:05:06,204:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-20 00:07:12,861:INFO:Soft dependency imported: pandas_profiling: 4.1.2
2023-07-20 00:07:16,349:WARNING:D:\anaconda\lib\site-packages\numba\core\decorators.py:262: NumbaDeprecationWarning: [1mnumba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.[0m
  warnings.warn(msg, NumbaDeprecationWarning)

2023-07-20 00:07:16,437:WARNING:D:\anaconda\lib\site-packages\visions\backends\shared\nan_handling.py:51: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def hasna(x: np.ndarray) -> bool:

2023-07-20 13:33:53,227:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-20 13:33:53,245:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-20 13:33:53,246:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-20 13:33:53,246:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-20 13:36:23,893:INFO:PyCaret RegressionExperiment
2023-07-20 13:36:23,893:INFO:Logging name: diamond
2023-07-20 13:36:23,893:INFO:ML Usecase: MLUsecase.REGRESSION
2023-07-20 13:36:23,893:INFO:version 3.0.4
2023-07-20 13:36:23,893:INFO:Initializing setup()
2023-07-20 13:36:23,904:INFO:self.USI: 9c89
2023-07-20 13:36:23,904:INFO:self._variable_keys: {'logging_param', 'X_test', 'target_param', 'exp_name_log', 'data', 'y_test', 'y_train', 'memory', 'log_plots_param', 'seed', 'y', 'idx', 'pipeline', 'gpu_param', 'html_param', '_available_plots', 'transform_target_param', 'n_jobs_param', 'fold_groups_param', 'X_train', 'X', 'fold_generator', 'USI', 'fold_shuffle_param', 'gpu_n_jobs_param', 'exp_id', '_ml_usecase'}
2023-07-20 13:36:23,904:INFO:Checking environment
2023-07-20 13:36:23,904:INFO:python_version: 3.9.13
2023-07-20 13:36:23,905:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-07-20 13:36:23,905:INFO:machine: AMD64
2023-07-20 13:36:23,905:INFO:platform: Windows-10-10.0.19045-SP0
2023-07-20 13:36:23,905:INFO:Memory: svmem(total=8463691776, available=2799898624, percent=66.9, used=5663793152, free=2799898624)
2023-07-20 13:36:23,905:INFO:Physical Core: 2
2023-07-20 13:36:23,905:INFO:Logical Core: 4
2023-07-20 13:36:23,905:INFO:Checking libraries
2023-07-20 13:36:23,905:INFO:System:
2023-07-20 13:36:23,905:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-07-20 13:36:23,905:INFO:executable: D:\anaconda\python.exe
2023-07-20 13:36:23,905:INFO:   machine: Windows-10-10.0.19045-SP0
2023-07-20 13:36:23,905:INFO:PyCaret required dependencies:
2023-07-20 13:36:23,905:INFO:                 pip: 23.1.2
2023-07-20 13:36:23,905:INFO:          setuptools: 67.8.0
2023-07-20 13:36:23,905:INFO:             pycaret: 3.0.4
2023-07-20 13:36:23,905:INFO:             IPython: 8.12.0
2023-07-20 13:36:23,905:INFO:          ipywidgets: 8.0.4
2023-07-20 13:36:23,905:INFO:                tqdm: 4.65.0
2023-07-20 13:36:23,905:INFO:               numpy: 1.23.5
2023-07-20 13:36:23,905:INFO:              pandas: 1.4.4
2023-07-20 13:36:23,905:INFO:              jinja2: 3.1.2
2023-07-20 13:36:23,905:INFO:               scipy: 1.10.1
2023-07-20 13:36:23,905:INFO:              joblib: 1.3.1
2023-07-20 13:36:23,905:INFO:             sklearn: 1.2.2
2023-07-20 13:36:23,905:INFO:                pyod: 1.1.0
2023-07-20 13:36:23,905:INFO:            imblearn: 0.11.0
2023-07-20 13:36:23,905:INFO:   category_encoders: 2.6.1
2023-07-20 13:36:23,905:INFO:            lightgbm: 3.3.5
2023-07-20 13:36:23,905:INFO:               numba: 0.57.0
2023-07-20 13:36:23,905:INFO:            requests: 2.29.0
2023-07-20 13:36:23,905:INFO:          matplotlib: 3.7.1
2023-07-20 13:36:23,905:INFO:          scikitplot: 0.3.7
2023-07-20 13:36:23,905:INFO:         yellowbrick: 1.5
2023-07-20 13:36:23,905:INFO:              plotly: 5.9.0
2023-07-20 13:36:23,905:INFO:    plotly-resampler: Not installed
2023-07-20 13:36:23,905:INFO:             kaleido: 0.2.1
2023-07-20 13:36:23,905:INFO:           schemdraw: 0.15
2023-07-20 13:36:23,905:INFO:         statsmodels: 0.13.5
2023-07-20 13:36:23,905:INFO:              sktime: 0.20.0
2023-07-20 13:36:23,905:INFO:               tbats: 1.1.3
2023-07-20 13:36:23,905:INFO:            pmdarima: 2.0.3
2023-07-20 13:36:23,905:INFO:              psutil: 5.9.0
2023-07-20 13:36:23,905:INFO:          markupsafe: 2.0.1
2023-07-20 13:36:23,905:INFO:             pickle5: Not installed
2023-07-20 13:36:23,905:INFO:         cloudpickle: 2.2.1
2023-07-20 13:36:23,905:INFO:         deprecation: 2.1.0
2023-07-20 13:36:23,905:INFO:              xxhash: 3.2.0
2023-07-20 13:36:23,905:INFO:           wurlitzer: 3.0.3
2023-07-20 13:36:23,905:INFO:PyCaret optional dependencies:
2023-07-20 13:36:23,921:INFO:                shap: Not installed
2023-07-20 13:36:23,921:INFO:           interpret: Not installed
2023-07-20 13:36:23,921:INFO:                umap: Not installed
2023-07-20 13:36:23,921:INFO:    pandas_profiling: 4.1.2
2023-07-20 13:36:23,921:INFO:  explainerdashboard: Not installed
2023-07-20 13:36:23,921:INFO:             autoviz: Not installed
2023-07-20 13:36:23,921:INFO:           fairlearn: Not installed
2023-07-20 13:36:23,921:INFO:          deepchecks: Not installed
2023-07-20 13:36:23,921:INFO:             xgboost: Not installed
2023-07-20 13:36:23,921:INFO:            catboost: Not installed
2023-07-20 13:36:23,921:INFO:              kmodes: Not installed
2023-07-20 13:36:23,921:INFO:             mlxtend: Not installed
2023-07-20 13:36:23,921:INFO:       statsforecast: Not installed
2023-07-20 13:36:23,921:INFO:        tune_sklearn: Not installed
2023-07-20 13:36:23,921:INFO:                 ray: Not installed
2023-07-20 13:36:23,921:INFO:            hyperopt: Not installed
2023-07-20 13:36:23,921:INFO:              optuna: Not installed
2023-07-20 13:36:23,921:INFO:               skopt: Not installed
2023-07-20 13:36:23,921:INFO:              mlflow: 2.5.0
2023-07-20 13:36:23,921:INFO:              gradio: Not installed
2023-07-20 13:36:23,921:INFO:             fastapi: Not installed
2023-07-20 13:36:23,921:INFO:             uvicorn: Not installed
2023-07-20 13:36:23,921:INFO:              m2cgen: Not installed
2023-07-20 13:36:23,921:INFO:           evidently: Not installed
2023-07-20 13:36:23,921:INFO:               fugue: Not installed
2023-07-20 13:36:23,921:INFO:           streamlit: Not installed
2023-07-20 13:36:23,921:INFO:             prophet: Not installed
2023-07-20 13:36:23,921:INFO:None
2023-07-20 13:36:23,921:INFO:Set up data.
2023-07-20 13:36:23,952:INFO:Set up train/test split.
2023-07-20 13:36:23,968:INFO:Set up index.
2023-07-20 13:36:23,968:INFO:Set up folding strategy.
2023-07-20 13:36:23,968:INFO:Assigning column types.
2023-07-20 13:36:23,968:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-20 13:36:23,968:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-20 13:36:23,983:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-20 13:36:23,999:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-20 13:36:24,077:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-20 13:36:24,139:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-20 13:36:24,139:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:25,392:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:25,392:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-20 13:36:25,408:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-20 13:36:25,408:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-20 13:36:25,486:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-20 13:36:25,533:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-20 13:36:25,533:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:25,533:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:25,533:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-07-20 13:36:25,533:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-20 13:36:25,549:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-20 13:36:25,611:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-20 13:36:25,658:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-20 13:36:25,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:25,658:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:25,674:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-20 13:36:25,674:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-20 13:36:25,736:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-20 13:36:25,799:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-20 13:36:25,799:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:25,799:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:25,799:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-07-20 13:36:25,814:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-20 13:36:25,877:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-20 13:36:25,939:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-20 13:36:25,939:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:25,939:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:25,955:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-20 13:36:26,017:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-20 13:36:26,064:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-20 13:36:26,064:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:26,064:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:26,064:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-07-20 13:36:26,158:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-20 13:36:26,205:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-20 13:36:26,205:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:26,205:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:26,283:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-20 13:36:26,330:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-20 13:36:26,330:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:26,330:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:26,330:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-20 13:36:26,408:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-20 13:36:26,470:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:26,470:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:26,549:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-20 13:36:26,595:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:26,595:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:26,595:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-07-20 13:36:26,752:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:26,752:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:26,877:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:26,877:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:26,908:INFO:Preparing preprocessing pipeline...
2023-07-20 13:36:26,908:INFO:Set up target transformation.
2023-07-20 13:36:26,908:INFO:Set up simple imputation.
2023-07-20 13:36:26,908:INFO:Set up encoding of ordinal features.
2023-07-20 13:36:26,908:INFO:Set up encoding of categorical features.
2023-07-20 13:36:26,924:INFO:Set up column name cleaning.
2023-07-20 13:36:27,189:INFO:Finished creating preprocessing pipeline.
2023-07-20 13:36:27,236:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\danca\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWra...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': AGSL    0
GIA     1
NaN    -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-07-20 13:36:27,236:INFO:Creating final display dataframe.
2023-07-20 13:36:27,799:INFO:Setup _display_container:                     Description         Value
0                    Session id          6808
1                        Target         Price
2                   Target type    Regression
3           Original data shape     (6000, 8)
4        Transformed data shape    (6000, 29)
5   Transformed train set shape    (4200, 29)
6    Transformed test set shape    (1800, 29)
7              Ordinal features             1
8              Numeric features             1
9          Categorical features             6
10                   Preprocess          True
11              Imputation type        simple
12           Numeric imputation          mean
13       Categorical imputation          mode
14     Maximum one-hot encoding            25
15              Encoding method          None
16             Transform target          True
17      Transform target method   yeo-johnson
18               Fold Generator         KFold
19                  Fold Number            10
20                     CPU Jobs            -1
21                      Use GPU         False
22               Log Experiment  MlflowLogger
23              Experiment Name       diamond
24                          USI          9c89
2023-07-20 13:36:28,003:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:28,003:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:28,128:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:28,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-20 13:36:28,144:INFO:Logging experiment in loggers
2023-07-20 13:36:28,569:INFO:SubProcess save_model() called ==================================
2023-07-20 13:36:28,631:INFO:Initializing save_model()
2023-07-20 13:36:28,631:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\danca\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWra...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': AGSL    0
GIA     1
NaN    -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\danca\AppData\Local\Temp\tmpw2sm51nu\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\danca\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWra...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': AGSL    0
GIA     1
NaN    -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-07-20 13:36:28,631:INFO:Adding model into prep_pipe
2023-07-20 13:36:28,631:WARNING:Only Model saved as it was a pipeline.
2023-07-20 13:36:28,647:INFO:C:\Users\danca\AppData\Local\Temp\tmpw2sm51nu\Transformation Pipeline.pkl saved in current working directory
2023-07-20 13:36:28,678:INFO:Pipeline(memory=FastMemory(location=C:\Users\danca\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWra...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': AGSL    0
GIA     1
NaN    -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-07-20 13:36:28,678:INFO:save_model() successfully completed......................................
2023-07-20 13:36:28,819:INFO:SubProcess save_model() end ==================================
2023-07-20 13:36:28,928:INFO:setup() successfully completed in 4.62s...............
2023-07-20 13:43:56,521:INFO:Initializing compare_models()
2023-07-20 13:43:56,521:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D1E1A95130>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001D1E1A95130>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-07-20 13:43:56,521:INFO:Checking exceptions
2023-07-20 13:43:56,528:INFO:Preparing display monitor
2023-07-20 13:43:56,615:INFO:Initializing Linear Regression
2023-07-20 13:43:56,616:INFO:Total runtime is 1.6689300537109375e-05 minutes
2023-07-20 13:43:56,626:INFO:SubProcess create_model() called ==================================
2023-07-20 13:43:56,626:INFO:Initializing create_model()
2023-07-20 13:43:56,627:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D1E1A95130>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1E3F4B370>, model_only=True, return_train_score=False, kwargs={})
2023-07-20 13:43:56,627:INFO:Checking exceptions
2023-07-20 13:43:56,627:INFO:Importing libraries
2023-07-20 13:43:56,628:INFO:Copying training dataset
2023-07-20 13:43:56,641:INFO:Defining folds
2023-07-20 13:43:56,642:INFO:Declaring metric variables
2023-07-20 13:43:56,657:INFO:Importing untrained model
2023-07-20 13:43:56,671:INFO:Linear Regression Imported successfully
2023-07-20 13:43:56,689:INFO:Starting cross validation
2023-07-20 13:43:56,717:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-20 13:44:11,215:INFO:Calculating mean and std
2023-07-20 13:44:11,215:INFO:Creating metrics dataframe
2023-07-20 13:44:11,716:INFO:Uploading results into container
2023-07-20 13:44:11,716:INFO:Uploading model into container now
2023-07-20 13:44:11,716:INFO:_master_model_container: 1
2023-07-20 13:44:11,716:INFO:_display_container: 2
2023-07-20 13:44:11,716:INFO:LinearRegression(n_jobs=-1)
2023-07-20 13:44:11,716:INFO:create_model() successfully completed......................................
2023-07-20 13:44:11,952:INFO:SubProcess create_model() end ==================================
2023-07-20 13:44:11,953:INFO:Creating metrics dataframe
2023-07-20 13:44:11,970:INFO:Initializing Lasso Regression
2023-07-20 13:44:11,970:INFO:Total runtime is 0.25592887004216514 minutes
2023-07-20 13:44:11,986:INFO:SubProcess create_model() called ==================================
2023-07-20 13:44:11,987:INFO:Initializing create_model()
2023-07-20 13:44:11,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D1E1A95130>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1E3F4B370>, model_only=True, return_train_score=False, kwargs={})
2023-07-20 13:44:11,988:INFO:Checking exceptions
2023-07-20 13:44:11,988:INFO:Importing libraries
2023-07-20 13:44:11,988:INFO:Copying training dataset
2023-07-20 13:44:12,017:INFO:Defining folds
2023-07-20 13:44:12,018:INFO:Declaring metric variables
2023-07-20 13:44:12,021:INFO:Importing untrained model
2023-07-20 13:44:12,043:INFO:Lasso Regression Imported successfully
2023-07-20 13:44:12,076:INFO:Starting cross validation
2023-07-20 13:44:12,083:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-20 13:44:17,911:INFO:Calculating mean and std
2023-07-20 13:44:17,911:INFO:Creating metrics dataframe
2023-07-20 13:44:18,308:INFO:Uploading results into container
2023-07-20 13:44:18,309:INFO:Uploading model into container now
2023-07-20 13:44:18,310:INFO:_master_model_container: 2
2023-07-20 13:44:18,310:INFO:_display_container: 2
2023-07-20 13:44:18,310:INFO:Lasso(random_state=6808)
2023-07-20 13:44:18,310:INFO:create_model() successfully completed......................................
2023-07-20 13:44:18,448:INFO:SubProcess create_model() end ==================================
2023-07-20 13:44:18,448:INFO:Creating metrics dataframe
2023-07-20 13:44:18,464:INFO:Initializing Ridge Regression
2023-07-20 13:44:18,464:INFO:Total runtime is 0.3641496260960897 minutes
2023-07-20 13:44:18,473:INFO:SubProcess create_model() called ==================================
2023-07-20 13:44:18,473:INFO:Initializing create_model()
2023-07-20 13:44:18,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D1E1A95130>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1E3F4B370>, model_only=True, return_train_score=False, kwargs={})
2023-07-20 13:44:18,474:INFO:Checking exceptions
2023-07-20 13:44:18,474:INFO:Importing libraries
2023-07-20 13:44:18,474:INFO:Copying training dataset
2023-07-20 13:44:18,501:INFO:Defining folds
2023-07-20 13:44:18,502:INFO:Declaring metric variables
2023-07-20 13:44:18,510:INFO:Importing untrained model
2023-07-20 13:44:18,526:INFO:Ridge Regression Imported successfully
2023-07-20 13:44:18,543:INFO:Starting cross validation
2023-07-20 13:44:18,548:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-20 13:44:24,010:INFO:Calculating mean and std
2023-07-20 13:44:24,010:INFO:Creating metrics dataframe
2023-07-20 13:44:24,529:INFO:Uploading results into container
2023-07-20 13:44:24,544:INFO:Uploading model into container now
2023-07-20 13:44:24,544:INFO:_master_model_container: 3
2023-07-20 13:44:24,544:INFO:_display_container: 2
2023-07-20 13:44:24,544:INFO:Ridge(random_state=6808)
2023-07-20 13:44:24,544:INFO:create_model() successfully completed......................................
2023-07-20 13:44:24,723:INFO:SubProcess create_model() end ==================================
2023-07-20 13:44:24,723:INFO:Creating metrics dataframe
2023-07-20 13:44:24,734:INFO:Initializing Elastic Net
2023-07-20 13:44:24,734:INFO:Total runtime is 0.4686508854230245 minutes
2023-07-20 13:44:24,755:INFO:SubProcess create_model() called ==================================
2023-07-20 13:44:24,756:INFO:Initializing create_model()
2023-07-20 13:44:24,757:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D1E1A95130>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1E3F4B370>, model_only=True, return_train_score=False, kwargs={})
2023-07-20 13:44:24,757:INFO:Checking exceptions
2023-07-20 13:44:24,758:INFO:Importing libraries
2023-07-20 13:44:24,758:INFO:Copying training dataset
2023-07-20 13:44:24,779:INFO:Defining folds
2023-07-20 13:44:24,779:INFO:Declaring metric variables
2023-07-20 13:44:24,802:INFO:Importing untrained model
2023-07-20 13:44:24,810:INFO:Elastic Net Imported successfully
2023-07-20 13:44:24,838:INFO:Starting cross validation
2023-07-20 13:44:24,845:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-20 13:44:29,796:INFO:Calculating mean and std
2023-07-20 13:44:29,796:INFO:Creating metrics dataframe
2023-07-20 13:44:30,204:INFO:Uploading results into container
2023-07-20 13:44:30,204:INFO:Uploading model into container now
2023-07-20 13:44:30,204:INFO:_master_model_container: 4
2023-07-20 13:44:30,204:INFO:_display_container: 2
2023-07-20 13:44:30,204:INFO:ElasticNet(random_state=6808)
2023-07-20 13:44:30,204:INFO:create_model() successfully completed......................................
2023-07-20 13:44:30,347:INFO:SubProcess create_model() end ==================================
2023-07-20 13:44:30,347:INFO:Creating metrics dataframe
2023-07-20 13:44:30,375:INFO:Initializing Least Angle Regression
2023-07-20 13:44:30,375:INFO:Total runtime is 0.5626696149508159 minutes
2023-07-20 13:44:30,384:INFO:SubProcess create_model() called ==================================
2023-07-20 13:44:30,386:INFO:Initializing create_model()
2023-07-20 13:44:30,386:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D1E1A95130>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1E3F4B370>, model_only=True, return_train_score=False, kwargs={})
2023-07-20 13:44:30,386:INFO:Checking exceptions
2023-07-20 13:44:30,386:INFO:Importing libraries
2023-07-20 13:44:30,386:INFO:Copying training dataset
2023-07-20 13:44:30,410:INFO:Defining folds
2023-07-20 13:44:30,412:INFO:Declaring metric variables
2023-07-20 13:44:30,425:INFO:Importing untrained model
2023-07-20 13:44:30,438:INFO:Least Angle Regression Imported successfully
2023-07-20 13:44:30,456:INFO:Starting cross validation
2023-07-20 13:44:30,462:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-20 13:44:31,504:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:31,504:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:31,504:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:31,520:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:31,536:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:31,536:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:31,536:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:31,536:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:32,588:WARNING:D:\anaconda\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.510e-04, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-07-20 13:44:33,105:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:33,105:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:33,105:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:33,105:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:33,105:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:33,188:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:33,189:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:33,191:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:33,191:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:33,191:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:33,325:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:33,325:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:33,325:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:33,325:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:33,325:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:33,528:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:33,544:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:33,544:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:33,544:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:33,544:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:34,556:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:34,556:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:34,556:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:34,556:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:34,556:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:34,670:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:34,670:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:34,670:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:34,670:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:34,670:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:35,865:INFO:Calculating mean and std
2023-07-20 13:44:35,865:INFO:Creating metrics dataframe
2023-07-20 13:44:36,278:INFO:Uploading results into container
2023-07-20 13:44:36,278:INFO:Uploading model into container now
2023-07-20 13:44:36,278:INFO:_master_model_container: 5
2023-07-20 13:44:36,278:INFO:_display_container: 2
2023-07-20 13:44:36,278:INFO:Lars(random_state=6808)
2023-07-20 13:44:36,278:INFO:create_model() successfully completed......................................
2023-07-20 13:44:36,426:INFO:SubProcess create_model() end ==================================
2023-07-20 13:44:36,426:INFO:Creating metrics dataframe
2023-07-20 13:44:36,434:INFO:Initializing Lasso Least Angle Regression
2023-07-20 13:44:36,434:INFO:Total runtime is 0.6636499285697938 minutes
2023-07-20 13:44:36,449:INFO:SubProcess create_model() called ==================================
2023-07-20 13:44:36,450:INFO:Initializing create_model()
2023-07-20 13:44:36,451:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D1E1A95130>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1E3F4B370>, model_only=True, return_train_score=False, kwargs={})
2023-07-20 13:44:36,451:INFO:Checking exceptions
2023-07-20 13:44:36,451:INFO:Importing libraries
2023-07-20 13:44:36,451:INFO:Copying training dataset
2023-07-20 13:44:36,470:INFO:Defining folds
2023-07-20 13:44:36,470:INFO:Declaring metric variables
2023-07-20 13:44:36,487:INFO:Importing untrained model
2023-07-20 13:44:36,494:INFO:Lasso Least Angle Regression Imported successfully
2023-07-20 13:44:36,513:INFO:Starting cross validation
2023-07-20 13:44:36,522:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-20 13:44:42,325:INFO:Calculating mean and std
2023-07-20 13:44:42,325:INFO:Creating metrics dataframe
2023-07-20 13:44:42,858:INFO:Uploading results into container
2023-07-20 13:44:42,858:INFO:Uploading model into container now
2023-07-20 13:44:42,858:INFO:_master_model_container: 6
2023-07-20 13:44:42,858:INFO:_display_container: 2
2023-07-20 13:44:42,858:INFO:LassoLars(random_state=6808)
2023-07-20 13:44:42,858:INFO:create_model() successfully completed......................................
2023-07-20 13:44:43,011:INFO:SubProcess create_model() end ==================================
2023-07-20 13:44:43,011:INFO:Creating metrics dataframe
2023-07-20 13:44:43,024:INFO:Initializing Orthogonal Matching Pursuit
2023-07-20 13:44:43,033:INFO:Total runtime is 0.7734925150871278 minutes
2023-07-20 13:44:43,041:INFO:SubProcess create_model() called ==================================
2023-07-20 13:44:43,042:INFO:Initializing create_model()
2023-07-20 13:44:43,042:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D1E1A95130>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1E3F4B370>, model_only=True, return_train_score=False, kwargs={})
2023-07-20 13:44:43,043:INFO:Checking exceptions
2023-07-20 13:44:43,043:INFO:Importing libraries
2023-07-20 13:44:43,043:INFO:Copying training dataset
2023-07-20 13:44:43,052:INFO:Defining folds
2023-07-20 13:44:43,052:INFO:Declaring metric variables
2023-07-20 13:44:43,061:INFO:Importing untrained model
2023-07-20 13:44:43,077:INFO:Orthogonal Matching Pursuit Imported successfully
2023-07-20 13:44:43,105:INFO:Starting cross validation
2023-07-20 13:44:43,111:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-20 13:44:48,013:INFO:Calculating mean and std
2023-07-20 13:44:48,015:INFO:Creating metrics dataframe
2023-07-20 13:44:48,413:INFO:Uploading results into container
2023-07-20 13:44:48,413:INFO:Uploading model into container now
2023-07-20 13:44:48,413:INFO:_master_model_container: 7
2023-07-20 13:44:48,413:INFO:_display_container: 2
2023-07-20 13:44:48,413:INFO:OrthogonalMatchingPursuit()
2023-07-20 13:44:48,413:INFO:create_model() successfully completed......................................
2023-07-20 13:44:48,562:INFO:SubProcess create_model() end ==================================
2023-07-20 13:44:48,562:INFO:Creating metrics dataframe
2023-07-20 13:44:48,579:INFO:Initializing Bayesian Ridge
2023-07-20 13:44:48,580:INFO:Total runtime is 0.86608251730601 minutes
2023-07-20 13:44:48,583:INFO:SubProcess create_model() called ==================================
2023-07-20 13:44:48,583:INFO:Initializing create_model()
2023-07-20 13:44:48,583:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D1E1A95130>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1E3F4B370>, model_only=True, return_train_score=False, kwargs={})
2023-07-20 13:44:48,583:INFO:Checking exceptions
2023-07-20 13:44:48,583:INFO:Importing libraries
2023-07-20 13:44:48,583:INFO:Copying training dataset
2023-07-20 13:44:48,607:INFO:Defining folds
2023-07-20 13:44:48,607:INFO:Declaring metric variables
2023-07-20 13:44:48,632:INFO:Importing untrained model
2023-07-20 13:44:48,639:INFO:Bayesian Ridge Imported successfully
2023-07-20 13:44:48,662:INFO:Starting cross validation
2023-07-20 13:44:48,668:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-20 13:44:53,929:INFO:Calculating mean and std
2023-07-20 13:44:53,929:INFO:Creating metrics dataframe
2023-07-20 13:44:54,523:INFO:Uploading results into container
2023-07-20 13:44:54,523:INFO:Uploading model into container now
2023-07-20 13:44:54,523:INFO:_master_model_container: 8
2023-07-20 13:44:54,523:INFO:_display_container: 2
2023-07-20 13:44:54,523:INFO:BayesianRidge()
2023-07-20 13:44:54,523:INFO:create_model() successfully completed......................................
2023-07-20 13:44:54,710:INFO:SubProcess create_model() end ==================================
2023-07-20 13:44:54,710:INFO:Creating metrics dataframe
2023-07-20 13:44:54,725:INFO:Initializing Passive Aggressive Regressor
2023-07-20 13:44:54,725:INFO:Total runtime is 0.9685114264488222 minutes
2023-07-20 13:44:54,747:INFO:SubProcess create_model() called ==================================
2023-07-20 13:44:54,748:INFO:Initializing create_model()
2023-07-20 13:44:54,749:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D1E1A95130>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1E3F4B370>, model_only=True, return_train_score=False, kwargs={})
2023-07-20 13:44:54,749:INFO:Checking exceptions
2023-07-20 13:44:54,750:INFO:Importing libraries
2023-07-20 13:44:54,750:INFO:Copying training dataset
2023-07-20 13:44:54,783:INFO:Defining folds
2023-07-20 13:44:54,783:INFO:Declaring metric variables
2023-07-20 13:44:54,806:INFO:Importing untrained model
2023-07-20 13:44:54,823:INFO:Passive Aggressive Regressor Imported successfully
2023-07-20 13:44:54,841:INFO:Starting cross validation
2023-07-20 13:44:54,854:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-20 13:44:55,979:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:55,980:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:55,981:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:55,981:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:55,981:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:56,077:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:56,077:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:56,077:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:56,077:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:56,077:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:56,233:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:56,233:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:56,233:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:56,233:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:56,233:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:56,311:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:56,311:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:56,311:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:56,311:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:56,311:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:57,819:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:57,819:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:57,819:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:57,834:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:57,834:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:58,053:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:58,037:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:58,053:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:58,053:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:58,053:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:58,053:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:58,053:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:58,085:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:58,085:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:58,085:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:58,257:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:58,273:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:58,273:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:58,273:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:58,273:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:59,503:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:59,503:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:59,503:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:59,503:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:59,503:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:59,683:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:59,683:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:59,683:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:59,683:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:44:59,683:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:01,298:INFO:Calculating mean and std
2023-07-20 13:45:01,298:INFO:Creating metrics dataframe
2023-07-20 13:45:01,745:INFO:Uploading results into container
2023-07-20 13:45:01,745:INFO:Uploading model into container now
2023-07-20 13:45:01,745:INFO:_master_model_container: 9
2023-07-20 13:45:01,745:INFO:_display_container: 2
2023-07-20 13:45:01,745:INFO:PassiveAggressiveRegressor(random_state=6808)
2023-07-20 13:45:01,745:INFO:create_model() successfully completed......................................
2023-07-20 13:45:01,879:WARNING:create_model() for PassiveAggressiveRegressor(random_state=6808) raised an exception or returned all 0.0, trying without fit_kwargs:
2023-07-20 13:45:01,928:WARNING:Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

2023-07-20 13:45:01,928:INFO:Initializing create_model()
2023-07-20 13:45:01,928:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D1E1A95130>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1E3F4B370>, model_only=True, return_train_score=False, kwargs={})
2023-07-20 13:45:01,929:INFO:Checking exceptions
2023-07-20 13:45:01,929:INFO:Importing libraries
2023-07-20 13:45:01,929:INFO:Copying training dataset
2023-07-20 13:45:01,933:INFO:Defining folds
2023-07-20 13:45:01,933:INFO:Declaring metric variables
2023-07-20 13:45:01,944:INFO:Importing untrained model
2023-07-20 13:45:01,953:INFO:Passive Aggressive Regressor Imported successfully
2023-07-20 13:45:01,974:INFO:Starting cross validation
2023-07-20 13:45:01,982:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-20 13:45:02,474:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:02,474:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:02,474:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:02,474:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:02,474:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:02,489:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:02,489:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:02,489:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:02,489:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:02,489:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:02,505:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:02,505:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:02,505:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:02,505:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:02,505:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:02,599:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:02,599:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:02,599:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:02,599:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:02,599:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:03,665:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:03,665:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:03,665:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:03,665:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:03,665:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:03,681:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:03,681:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:03,681:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:03,681:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:03,681:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:03,744:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:03,744:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:03,744:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:03,744:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:03,744:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:03,775:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:03,775:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:03,790:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:03,790:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:03,790:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:04,684:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:04,684:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:04,684:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:04,684:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:04,684:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:04,731:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 519, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:04,731:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:04,731:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:04,731:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:04,731:WARNING:D:\anaconda\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "D:\anaconda\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "D:\anaconda\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-20 13:45:06,237:INFO:Calculating mean and std
2023-07-20 13:45:06,237:INFO:Creating metrics dataframe
2023-07-20 13:45:06,660:INFO:Uploading results into container
2023-07-20 13:45:06,660:INFO:Uploading model into container now
2023-07-20 13:45:06,660:INFO:_master_model_container: 10
2023-07-20 13:45:06,660:INFO:_display_container: 2
2023-07-20 13:45:06,660:INFO:PassiveAggressiveRegressor(random_state=6808)
2023-07-20 13:45:06,660:INFO:create_model() successfully completed......................................
2023-07-20 13:45:06,797:ERROR:create_model() for PassiveAggressiveRegressor(random_state=6808) raised an exception or returned all 0.0:
2023-07-20 13:45:06,797:ERROR:Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\anaconda\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 812, in compare_models
    assert (
AssertionError

2023-07-20 13:45:06,797:INFO:Initializing Huber Regressor
2023-07-20 13:45:06,797:INFO:Total runtime is 1.1697088956832886 minutes
2023-07-20 13:45:06,812:INFO:SubProcess create_model() called ==================================
2023-07-20 13:45:06,812:INFO:Initializing create_model()
2023-07-20 13:45:06,817:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D1E1A95130>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1E3F4B370>, model_only=True, return_train_score=False, kwargs={})
2023-07-20 13:45:06,817:INFO:Checking exceptions
2023-07-20 13:45:06,818:INFO:Importing libraries
2023-07-20 13:45:06,818:INFO:Copying training dataset
2023-07-20 13:45:06,830:INFO:Defining folds
2023-07-20 13:45:06,830:INFO:Declaring metric variables
2023-07-20 13:45:06,839:INFO:Importing untrained model
2023-07-20 13:45:06,839:INFO:Huber Regressor Imported successfully
2023-07-20 13:45:06,862:INFO:Starting cross validation
2023-07-20 13:45:06,869:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-20 13:45:07,627:WARNING:D:\anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-20 13:45:07,664:WARNING:D:\anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-20 13:45:07,680:WARNING:D:\anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-20 13:45:09,548:WARNING:D:\anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-20 13:45:09,626:WARNING:D:\anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-20 13:45:09,750:WARNING:D:\anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-20 13:45:09,812:WARNING:D:\anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-20 13:45:11,803:WARNING:D:\anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-20 13:45:11,859:WARNING:D:\anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-20 13:45:13,732:INFO:Calculating mean and std
2023-07-20 13:45:13,732:INFO:Creating metrics dataframe
2023-07-20 13:45:14,312:INFO:Uploading results into container
2023-07-20 13:45:14,312:INFO:Uploading model into container now
2023-07-20 13:45:14,312:INFO:_master_model_container: 11
2023-07-20 13:45:14,312:INFO:_display_container: 2
2023-07-20 13:45:14,312:INFO:HuberRegressor()
2023-07-20 13:45:14,312:INFO:create_model() successfully completed......................................
2023-07-20 13:45:14,463:INFO:SubProcess create_model() end ==================================
2023-07-20 13:45:14,463:INFO:Creating metrics dataframe
2023-07-20 13:45:14,489:INFO:Initializing K Neighbors Regressor
2023-07-20 13:45:14,489:INFO:Total runtime is 1.2978979667027792 minutes
2023-07-20 13:45:14,489:INFO:SubProcess create_model() called ==================================
2023-07-20 13:45:14,489:INFO:Initializing create_model()
2023-07-20 13:45:14,489:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D1E1A95130>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1E3F4B370>, model_only=True, return_train_score=False, kwargs={})
2023-07-20 13:45:14,489:INFO:Checking exceptions
2023-07-20 13:45:14,489:INFO:Importing libraries
2023-07-20 13:45:14,489:INFO:Copying training dataset
2023-07-20 13:45:14,511:INFO:Defining folds
2023-07-20 13:45:14,525:INFO:Declaring metric variables
2023-07-20 13:45:14,542:INFO:Importing untrained model
2023-07-20 13:45:14,556:INFO:K Neighbors Regressor Imported successfully
2023-07-20 13:45:14,573:INFO:Starting cross validation
2023-07-20 13:45:14,583:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-20 13:45:20,146:INFO:Calculating mean and std
2023-07-20 13:45:20,146:INFO:Creating metrics dataframe
2023-07-20 13:45:20,584:INFO:Uploading results into container
2023-07-20 13:45:20,584:INFO:Uploading model into container now
2023-07-20 13:45:20,584:INFO:_master_model_container: 12
2023-07-20 13:45:20,584:INFO:_display_container: 2
2023-07-20 13:45:20,584:INFO:KNeighborsRegressor(n_jobs=-1)
2023-07-20 13:45:20,584:INFO:create_model() successfully completed......................................
2023-07-20 13:45:20,713:INFO:SubProcess create_model() end ==================================
2023-07-20 13:45:20,713:INFO:Creating metrics dataframe
2023-07-20 13:45:20,746:INFO:Initializing Decision Tree Regressor
2023-07-20 13:45:20,746:INFO:Total runtime is 1.402183465162913 minutes
2023-07-20 13:45:20,755:INFO:SubProcess create_model() called ==================================
2023-07-20 13:45:20,756:INFO:Initializing create_model()
2023-07-20 13:45:20,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D1E1A95130>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1E3F4B370>, model_only=True, return_train_score=False, kwargs={})
2023-07-20 13:45:20,756:INFO:Checking exceptions
2023-07-20 13:45:20,757:INFO:Importing libraries
2023-07-20 13:45:20,757:INFO:Copying training dataset
2023-07-20 13:45:20,767:INFO:Defining folds
2023-07-20 13:45:20,767:INFO:Declaring metric variables
2023-07-20 13:45:20,788:INFO:Importing untrained model
2023-07-20 13:45:20,810:INFO:Decision Tree Regressor Imported successfully
2023-07-20 13:45:20,826:INFO:Starting cross validation
2023-07-20 13:45:20,826:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-20 13:45:27,107:INFO:Calculating mean and std
2023-07-20 13:45:27,107:INFO:Creating metrics dataframe
2023-07-20 13:45:27,703:INFO:Uploading results into container
2023-07-20 13:45:27,718:INFO:Uploading model into container now
2023-07-20 13:45:27,718:INFO:_master_model_container: 13
2023-07-20 13:45:27,718:INFO:_display_container: 2
2023-07-20 13:45:27,718:INFO:DecisionTreeRegressor(random_state=6808)
2023-07-20 13:45:27,718:INFO:create_model() successfully completed......................................
2023-07-20 13:45:27,892:INFO:SubProcess create_model() end ==================================
2023-07-20 13:45:27,892:INFO:Creating metrics dataframe
2023-07-20 13:45:27,908:INFO:Initializing Random Forest Regressor
2023-07-20 13:45:27,908:INFO:Total runtime is 1.5215500076611836 minutes
2023-07-20 13:45:27,931:INFO:SubProcess create_model() called ==================================
2023-07-20 13:45:27,931:INFO:Initializing create_model()
2023-07-20 13:45:27,932:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D1E1A95130>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1E3F4B370>, model_only=True, return_train_score=False, kwargs={})
2023-07-20 13:45:27,933:INFO:Checking exceptions
2023-07-20 13:45:27,933:INFO:Importing libraries
2023-07-20 13:45:27,933:INFO:Copying training dataset
2023-07-20 13:45:27,956:INFO:Defining folds
2023-07-20 13:45:27,958:INFO:Declaring metric variables
2023-07-20 13:45:27,973:INFO:Importing untrained model
2023-07-20 13:45:27,987:INFO:Random Forest Regressor Imported successfully
2023-07-20 13:45:28,011:INFO:Starting cross validation
2023-07-20 13:45:28,021:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-20 13:45:31,937:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-20 13:45:36,346:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-20 13:45:43,040:INFO:Calculating mean and std
2023-07-20 13:45:43,040:INFO:Creating metrics dataframe
2023-07-20 13:45:43,729:INFO:Uploading results into container
2023-07-20 13:45:43,729:INFO:Uploading model into container now
2023-07-20 13:45:43,729:INFO:_master_model_container: 14
2023-07-20 13:45:43,729:INFO:_display_container: 2
2023-07-20 13:45:43,729:INFO:RandomForestRegressor(n_jobs=-1, random_state=6808)
2023-07-20 13:45:43,729:INFO:create_model() successfully completed......................................
2023-07-20 13:45:43,909:INFO:SubProcess create_model() end ==================================
2023-07-20 13:45:43,909:INFO:Creating metrics dataframe
2023-07-20 13:45:43,925:INFO:Initializing Extra Trees Regressor
2023-07-20 13:45:43,925:INFO:Total runtime is 1.7884982426961262 minutes
2023-07-20 13:45:43,948:INFO:SubProcess create_model() called ==================================
2023-07-20 13:45:43,949:INFO:Initializing create_model()
2023-07-20 13:45:43,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D1E1A95130>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1E3F4B370>, model_only=True, return_train_score=False, kwargs={})
2023-07-20 13:45:43,951:INFO:Checking exceptions
2023-07-20 13:45:43,951:INFO:Importing libraries
2023-07-20 13:45:43,951:INFO:Copying training dataset
2023-07-20 13:45:43,967:INFO:Defining folds
2023-07-20 13:45:43,968:INFO:Declaring metric variables
2023-07-20 13:45:43,985:INFO:Importing untrained model
2023-07-20 13:45:44,001:INFO:Extra Trees Regressor Imported successfully
2023-07-20 13:45:44,024:INFO:Starting cross validation
2023-07-20 13:45:44,039:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-20 13:45:47,618:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-20 13:45:47,633:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-20 13:45:49,564:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-20 13:45:53,090:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-20 13:45:53,153:WARNING:D:\anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-20 13:45:59,598:INFO:Calculating mean and std
2023-07-20 13:45:59,598:INFO:Creating metrics dataframe
2023-07-20 13:46:00,255:INFO:Uploading results into container
2023-07-20 13:46:00,255:INFO:Uploading model into container now
2023-07-20 13:46:00,255:INFO:_master_model_container: 15
2023-07-20 13:46:00,255:INFO:_display_container: 2
2023-07-20 13:46:00,255:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6808)
2023-07-20 13:46:00,255:INFO:create_model() successfully completed......................................
2023-07-20 13:46:00,442:INFO:SubProcess create_model() end ==================================
2023-07-20 13:46:00,442:INFO:Creating metrics dataframe
2023-07-20 13:46:00,486:INFO:Initializing AdaBoost Regressor
2023-07-20 13:46:00,487:INFO:Total runtime is 2.0645439942677815 minutes
2023-07-20 13:46:00,495:INFO:SubProcess create_model() called ==================================
2023-07-20 13:46:00,496:INFO:Initializing create_model()
2023-07-20 13:46:00,496:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D1E1A95130>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1E3F4B370>, model_only=True, return_train_score=False, kwargs={})
2023-07-20 13:46:00,497:INFO:Checking exceptions
2023-07-20 13:46:00,497:INFO:Importing libraries
2023-07-20 13:46:00,498:INFO:Copying training dataset
2023-07-20 13:46:00,510:INFO:Defining folds
2023-07-20 13:46:00,512:INFO:Declaring metric variables
2023-07-20 13:46:00,528:INFO:Importing untrained model
2023-07-20 13:46:00,540:INFO:AdaBoost Regressor Imported successfully
2023-07-20 13:46:00,574:INFO:Starting cross validation
2023-07-20 13:46:00,574:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-20 13:46:08,457:INFO:Calculating mean and std
2023-07-20 13:46:08,457:INFO:Creating metrics dataframe
2023-07-20 13:46:08,942:INFO:Uploading results into container
2023-07-20 13:46:08,942:INFO:Uploading model into container now
2023-07-20 13:46:08,942:INFO:_master_model_container: 16
2023-07-20 13:46:08,942:INFO:_display_container: 2
2023-07-20 13:46:08,942:INFO:AdaBoostRegressor(random_state=6808)
2023-07-20 13:46:08,942:INFO:create_model() successfully completed......................................
2023-07-20 13:46:09,088:INFO:SubProcess create_model() end ==================================
2023-07-20 13:46:09,088:INFO:Creating metrics dataframe
2023-07-20 13:46:09,099:INFO:Initializing Gradient Boosting Regressor
2023-07-20 13:46:09,099:INFO:Total runtime is 2.208066177368164 minutes
2023-07-20 13:46:09,114:INFO:SubProcess create_model() called ==================================
2023-07-20 13:46:09,115:INFO:Initializing create_model()
2023-07-20 13:46:09,116:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D1E1A95130>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1E3F4B370>, model_only=True, return_train_score=False, kwargs={})
2023-07-20 13:46:09,116:INFO:Checking exceptions
2023-07-20 13:46:09,116:INFO:Importing libraries
2023-07-20 13:46:09,116:INFO:Copying training dataset
2023-07-20 13:46:09,128:INFO:Defining folds
2023-07-20 13:46:09,128:INFO:Declaring metric variables
2023-07-20 13:46:09,154:INFO:Importing untrained model
2023-07-20 13:46:09,156:INFO:Gradient Boosting Regressor Imported successfully
2023-07-20 13:46:09,173:INFO:Starting cross validation
2023-07-20 13:46:09,185:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-20 13:46:17,865:INFO:Calculating mean and std
2023-07-20 13:46:17,865:INFO:Creating metrics dataframe
2023-07-20 13:46:18,584:INFO:Uploading results into container
2023-07-20 13:46:18,584:INFO:Uploading model into container now
2023-07-20 13:46:18,584:INFO:_master_model_container: 17
2023-07-20 13:46:18,584:INFO:_display_container: 2
2023-07-20 13:46:18,584:INFO:GradientBoostingRegressor(random_state=6808)
2023-07-20 13:46:18,584:INFO:create_model() successfully completed......................................
2023-07-20 13:46:18,759:INFO:SubProcess create_model() end ==================================
2023-07-20 13:46:18,759:INFO:Creating metrics dataframe
2023-07-20 13:46:18,790:INFO:Initializing Light Gradient Boosting Machine
2023-07-20 13:46:18,790:INFO:Total runtime is 2.3695922772089637 minutes
2023-07-20 13:46:18,805:INFO:SubProcess create_model() called ==================================
2023-07-20 13:46:18,806:INFO:Initializing create_model()
2023-07-20 13:46:18,806:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D1E1A95130>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1E3F4B370>, model_only=True, return_train_score=False, kwargs={})
2023-07-20 13:46:18,807:INFO:Checking exceptions
2023-07-20 13:46:18,807:INFO:Importing libraries
2023-07-20 13:46:18,808:INFO:Copying training dataset
2023-07-20 13:46:18,823:INFO:Defining folds
2023-07-20 13:46:18,823:INFO:Declaring metric variables
2023-07-20 13:46:18,840:INFO:Importing untrained model
2023-07-20 13:46:18,858:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-20 13:46:18,876:INFO:Starting cross validation
2023-07-20 13:46:18,880:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-20 13:46:27,335:INFO:Calculating mean and std
2023-07-20 13:46:27,335:INFO:Creating metrics dataframe
2023-07-20 13:46:27,853:INFO:Uploading results into container
2023-07-20 13:46:27,853:INFO:Uploading model into container now
2023-07-20 13:46:27,853:INFO:_master_model_container: 18
2023-07-20 13:46:27,853:INFO:_display_container: 2
2023-07-20 13:46:27,853:INFO:LGBMRegressor(random_state=6808)
2023-07-20 13:46:27,853:INFO:create_model() successfully completed......................................
2023-07-20 13:46:27,995:INFO:SubProcess create_model() end ==================================
2023-07-20 13:46:27,995:INFO:Creating metrics dataframe
2023-07-20 13:46:28,010:INFO:Initializing Dummy Regressor
2023-07-20 13:46:28,010:INFO:Total runtime is 2.523262524604797 minutes
2023-07-20 13:46:28,023:INFO:SubProcess create_model() called ==================================
2023-07-20 13:46:28,024:INFO:Initializing create_model()
2023-07-20 13:46:28,024:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D1E1A95130>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1E3F4B370>, model_only=True, return_train_score=False, kwargs={})
2023-07-20 13:46:28,024:INFO:Checking exceptions
2023-07-20 13:46:28,025:INFO:Importing libraries
2023-07-20 13:46:28,025:INFO:Copying training dataset
2023-07-20 13:46:28,035:INFO:Defining folds
2023-07-20 13:46:28,036:INFO:Declaring metric variables
2023-07-20 13:46:28,054:INFO:Importing untrained model
2023-07-20 13:46:28,068:INFO:Dummy Regressor Imported successfully
2023-07-20 13:46:28,083:INFO:Starting cross validation
2023-07-20 13:46:28,083:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-20 13:46:34,862:INFO:Calculating mean and std
2023-07-20 13:46:34,882:INFO:Creating metrics dataframe
2023-07-20 13:46:35,425:INFO:Uploading results into container
2023-07-20 13:46:35,425:INFO:Uploading model into container now
2023-07-20 13:46:35,425:INFO:_master_model_container: 19
2023-07-20 13:46:35,425:INFO:_display_container: 2
2023-07-20 13:46:35,425:INFO:DummyRegressor()
2023-07-20 13:46:35,425:INFO:create_model() successfully completed......................................
2023-07-20 13:46:35,550:INFO:SubProcess create_model() end ==================================
2023-07-20 13:46:35,550:INFO:Creating metrics dataframe
2023-07-20 13:46:35,599:INFO:Initializing create_model()
2023-07-20 13:46:35,600:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D1E1A95130>, estimator=LGBMRegressor(random_state=6808), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-20 13:46:35,600:INFO:Checking exceptions
2023-07-20 13:46:35,603:INFO:Importing libraries
2023-07-20 13:46:35,603:INFO:Copying training dataset
2023-07-20 13:46:35,631:INFO:Defining folds
2023-07-20 13:46:35,632:INFO:Declaring metric variables
2023-07-20 13:46:35,634:INFO:Importing untrained model
2023-07-20 13:46:35,634:INFO:Declaring custom model
2023-07-20 13:46:35,637:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-20 13:46:35,641:INFO:Cross validation set to False
2023-07-20 13:46:35,642:INFO:Fitting Model
2023-07-20 13:46:36,508:INFO:LGBMRegressor(random_state=6808)
2023-07-20 13:46:36,508:INFO:create_model() successfully completed......................................
2023-07-20 13:46:36,635:INFO:Creating Dashboard logs
2023-07-20 13:46:36,635:INFO:Model: Light Gradient Boosting Machine
2023-07-20 13:46:36,729:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 6808, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-07-20 13:46:37,011:INFO:Initializing predict_model()
2023-07-20 13:46:37,011:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D1E1A95130>, estimator=LGBMRegressor(random_state=6808), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D1E41FE430>)
2023-07-20 13:46:37,011:INFO:Checking exceptions
2023-07-20 13:46:37,011:INFO:Preloading libraries
2023-07-20 13:46:37,498:WARNING:D:\anaconda\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-07-20 13:46:38,075:INFO:Creating Dashboard logs
2023-07-20 13:46:38,091:INFO:Model: Gradient Boosting Regressor
2023-07-20 13:46:38,179:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 6808, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-07-20 13:46:38,970:INFO:Creating Dashboard logs
2023-07-20 13:46:38,986:INFO:Model: Random Forest Regressor
2023-07-20 13:46:39,065:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 6808, 'verbose': 0, 'warm_start': False}
2023-07-20 13:46:39,818:INFO:Creating Dashboard logs
2023-07-20 13:46:39,838:INFO:Model: Extra Trees Regressor
2023-07-20 13:46:39,930:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 6808, 'verbose': 0, 'warm_start': False}
2023-07-20 13:46:40,694:INFO:Creating Dashboard logs
2023-07-20 13:46:40,710:INFO:Model: Decision Tree Regressor
2023-07-20 13:46:40,797:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 6808, 'splitter': 'best'}
2023-07-20 13:46:41,526:INFO:Creating Dashboard logs
2023-07-20 13:46:41,526:INFO:Model: AdaBoost Regressor
2023-07-20 13:46:41,629:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 6808}
2023-07-20 13:46:42,356:INFO:Creating Dashboard logs
2023-07-20 13:46:42,356:INFO:Model: K Neighbors Regressor
2023-07-20 13:46:42,446:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-07-20 13:46:43,190:INFO:Creating Dashboard logs
2023-07-20 13:46:43,190:INFO:Model: Orthogonal Matching Pursuit
2023-07-20 13:46:43,279:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-07-20 13:46:44,003:INFO:Creating Dashboard logs
2023-07-20 13:46:44,003:INFO:Model: Lasso Least Angle Regression
2023-07-20 13:46:44,098:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 6808, 'verbose': False}
2023-07-20 13:46:44,835:INFO:Creating Dashboard logs
2023-07-20 13:46:44,835:INFO:Model: Lasso Regression
2023-07-20 13:46:44,929:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 6808, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-07-20 13:46:45,869:INFO:Creating Dashboard logs
2023-07-20 13:46:45,884:INFO:Model: Elastic Net
2023-07-20 13:46:45,995:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 6808, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-07-20 13:46:47,107:INFO:Creating Dashboard logs
2023-07-20 13:46:47,118:INFO:Model: Dummy Regressor
2023-07-20 13:46:47,269:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-07-20 13:46:48,474:INFO:Creating Dashboard logs
2023-07-20 13:46:48,474:INFO:Model: Huber Regressor
2023-07-20 13:46:48,595:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-07-20 13:46:49,781:INFO:Creating Dashboard logs
2023-07-20 13:46:49,786:INFO:Model: Ridge Regression
2023-07-20 13:46:49,888:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 6808, 'solver': 'auto', 'tol': 0.0001}
2023-07-20 13:46:50,720:INFO:Creating Dashboard logs
2023-07-20 13:46:50,736:INFO:Model: Bayesian Ridge
2023-07-20 13:46:50,845:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2023-07-20 13:46:51,655:INFO:Creating Dashboard logs
2023-07-20 13:46:51,671:INFO:Model: Linear Regression
2023-07-20 13:46:51,762:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'positive': False}
2023-07-20 13:46:52,581:INFO:Creating Dashboard logs
2023-07-20 13:46:52,597:INFO:Model: Least Angle Regression
2023-07-20 13:46:52,695:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 6808, 'verbose': False}
2023-07-20 13:46:53,586:INFO:_master_model_container: 19
2023-07-20 13:46:53,586:INFO:_display_container: 2
2023-07-20 13:46:53,588:INFO:LGBMRegressor(random_state=6808)
2023-07-20 13:46:53,589:INFO:compare_models() successfully completed......................................
